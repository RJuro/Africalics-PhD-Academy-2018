{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - supervised and other text based fun",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJuro/Africalics-PhD-Academy-2018/blob/master/notebooks/NLP_supervised_and_other_text_based_fun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGaB5hfmlfbY",
        "colab_type": "text"
      },
      "source": [
        "Roman Jurowetzki, Aalborg University\n",
        "In part based on the Intro from the DeepNLP course by Dan Anastasyev - https://github.com/DanAnastasyev/DeepNLP-Course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0_Khhi7V7NH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f51a4815-7766-4e4a-d439-c7694ca1d872"
      },
      "source": [
        "# Some initial downloads and installs\n",
        "\n",
        "!wget -O imdb.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vrQ5czMHoO3pEnmofFskymXMkq_u1dPc\"\n",
        "!unzip imdb.zip\n",
        "!pip -q install eli5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imdb.zip\n",
            "  inflating: test.tsv                \n",
            "  inflating: train.tsv               \n",
            "\u001b[K     |████████████████████████████████| 112kB 4.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTAGr6IjQye",
        "colab_type": "text"
      },
      "source": [
        "# Supervised ML & Text & some other things\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/lyp8lvbphdnuhd2/antique-classic-close-up-1995842.jpg?dl=1)\n",
        "\n",
        "In this tutorial we will be using the well known IMDB movie review dataset for simple classification with different vectorization techniques:\n",
        "\n",
        "\n",
        "*   Simple bag-of-words\n",
        "*   TF-IDF\n",
        "*   LSI / SVD\n",
        "*   Average embeddings (general public domain vectors)\n",
        "*   Average embeddings (custom-trained vectors)\n",
        "*   TF-IDF weighted embeddings\n",
        "\n",
        "We will also look at some more recent approaches to model explainability i.e. \"Why did the model decide this or that?\"\n",
        "\n",
        "\n",
        "Finally, we will look at a simple approach to building a **semantic search** based on vector-similarity\n",
        "\n",
        "\n",
        "\n",
        "Disclamer: \n",
        "\n",
        "- This is more a demo than a class - thus please don't be distracted by sometimes complex code. If you are interested, you can review the material later\n",
        "- The more things get complex, the more options we have - yet this means also that complex models often underperform \"out-of-the-box\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1m5wMRWTBn",
        "colab_type": "code",
        "outputId": "2265c0d4-1cb5-458d-c697-3ea19cd9a996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!head train.tsv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_positive\treview\r\n",
            "0\t\"Dreamgirls, despite its fistful of Tony wins in an incredibly weak year on Broadway, has never been what one would call a jewel in the crown of stage musicals. However, that is not to say that in the right cinematic hands it could not be fleshed out and polished into something worthwhile on-screen. Unfortunately, what transfers to the screen is basically a slavishly faithful version of the stage hit with all of its inherent weaknesses intact. First, the score has never been one of the strong points of this production and the film does not change that factor. There are lots of songs (perhaps too many?), but few of them are especially memorable. The closest any come to catchy tunes are the title song and One Night Only - the much acclaimed And I Am Telling You That I Am Not Going is less a great song than it is a dramatic set piece for the character of Effie (Jennifer Hudson). The film is slick and technically well-produced, but the story and characters are surprisingly thin and lacking in any resonance. There is some interest in the opening moments, watching Jamie Foxx's Svengali-like manager manipulate his acts to the top, but that takes a back seat in the latter portion of the film, when the story conveniently tries to cast him as a villain, despite his having been right from a business stand-point for a good majority of the film. Beyonce Knowles is lovely and sings her songs perfectly well, but is stuck with a character who is basically all surface glitz. Anika Noni Rose as the third member of the Dreamgirls trio literally has nothing to do for the entire film. Eddie Murphy acquits himself well as a singer obviously based on James Brown, but the role is not especially meaty and ultimately has little impact. Foxx would seem ideal casting, but he seems oddly withdrawn and bored. The film's biggest selling point is surely former American Idol contestant/Oscar winner Jennifer Hudson in the central role of Effie White, the temperamental singer who gets booted from the group and makes a triumphant closing act return. For me, Effie has always been a big problem in both the show and the movie. The film obviously wants you to feel sorry for her and rather ham-handedly takes her side, but I have never been sure that this character deserves that kind of devotion. From the start, Effie conducts herself for the most part like an obnoxious, egotistical, self-centered diva, who is more interested in what everyone else can do for her rather than having much vested interest in the group of which she is a part. When she is booted from the group for her unprofessionalism and bad attitude, the charges are more than well-founded, but the stage show/film seem to think Effie should be cut unlimited slack simply because she has a great voice. Even though the film tries to soften some of Effie's harder edges to make her more likable, the charges still stand. Her story becomes more manipulative by suggesting she should have our further sympathy because she is an unwed mother struggling to raise her daughter - using the implication that (much like the talent card) motherhood immediately makes any behavior excusable. Indeed the only big effort the film makes to show Effie's mothering is to tell us about it and then include a scene where she barks at her daughter in the unemployment office, insists that the girl has \"\"no father\"\" and then refuse to look for gainful employment to support them since singing is all she knows. In the hands of a skillful actress, the gaps could perhaps have been remedied with technique and charisma. Unfortunately, Hudson is not that actress. She sings well, but the dialog-driven moments do not come naturally to her nor do high emotional moments. Effie's signature moment (the aforementioned And I Am Telling You... number) is well-sung by Hudson, but emotionally flat in the acting department. Effie is supposed to expressing her rage and desperation at her predicament, but Hudson comes off as a cabaret performer belting out a hot number. All in all, not quite the emotional highlight one expects. The latter portion of the film is basically a predictable melange of events that maneuver Foxx into Hudson's earlier position and allow her to strut back in and lord it over everyone. Foxx's criminal offenses in the film are undoubtedly par for the course of many struggling record producers, but the film's seeming implication that he has it coming because he helped usher in the disco era is rather ridiculous, not to mention pretentious and condescending, particularly coming from a film with all of the depth of a puddle. The end result is a faithful rendition of the stage hit, drained of emotion, energy or anything that can be described as dynamic.\"\r\n",
            "0\tThis show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.<br /><br />It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality. <br /><br />This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.<br /><br />It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.\r\n",
            "1\tI simply love this movie. I also love the Ramones, so I am sorta biased to begin with in the first place. There isn't a lot of critical praise to give this film, either you like it or you don't. I think it's a great cult movie.\r\n",
            "0\t\"Spoilers ahead if you want to call them that...<br /><br />I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...<br /><br />THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"\"effort\"\".<br /><br />THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"\"Woah, you totally freaked me out\"\" and \"\"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\"\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.<br /><br />THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...<br /><br />THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"\"Woah you totally freaked me out\"\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.<br /><br />TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.<br /><br />Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.<br /><br />Signing off... Amanda Christmas\"\r\n",
            "1\t\"My all-time favorite movie! I have seen many movies, but this one beats them all! Excelent acting, wonderful story. You will, as a \"\"normal\"\" caring person start to love George. Altough he is an actor, he is also himself and a very lovable person. And maby most important thing: you will learn to respect & look different to people with Down Syndrome.\"\r\n",
            "1\tWonderful film, one of the best horror films of the 70s. She is realistic settings and atmospheres. As usual it was inevitable the usual negative comments. I have noticed that most horror films of a certain period many times fail to reach even sufficiency. Obviously because most horror movies are old and must be denigrati, is like a mental mechanism that moves the minds of the potential of music critics here.<br /><br />Before you read the review already knew what was the final judgment. In the film a good gift because 10 is really well done. Raines reads quite well and the film as a way in which it was produced reminds me a lot of Kubrick films. He really impression. Excellent film really. I consider a film anthology of years'70.\r\n",
            "0\tand shot in Vancouver with the 'mountains' of the low country of South Carolina visible in the background. For heaven's sake, they should have reset the location. There are no coastal mountains in South Carolina. Period.<br /><br />Lame visuals. They should have been beautiful. And the story limped along.<br /><br />I really don't understand why it was such a hit as a book, although I have to admit it's one I haven't read as yet. Usually I read the book and give the film a miss. There was nothing in this movie that made me want to buy the book, or even borrow it from the library.<br /><br />Verdict: The Mermaid Chair seemed pretty shallow to moi.\r\n",
            "1\tThis is the best dub I've ever heard by Disney, as well as the best adaptation since the biggest abuse ever on soundtrack, themes, characters, dialogues in Kiki Delivery Service. Urrrghhh<br /><br />This one has different atmosphere, especially the deviation from the common heroine. This one has both hero and heroine (although I don't really endorse the use of hero & heroine here, since Miyazaki is out from the stereotype & common theme). As usual, after being introduced by Spirited away, amazed by Mononoke, troubled by Grave of Fireflies, and deeply touched by Majo no Takkyuubin , this one start with a bit doubt in my part. Wondering if this will be the first Ghibi's dud. Well, in the end just like Only Yesterday and Whisper of the Heart, I ended up giving 10 rating. I'd give 9.8 rating, but the additional 0.2 is there to share the good feeling by encouraging people to see the movie.<br /><br />SPOILER Somehow I see this as a sad movie, people die in this one, the lonely robot, the abandoned place, and it ends with destruction. It is as if mankind really can't live with too much power. The collapsing scene gave me patches of Metropolis ending. It's just sad somehow. The plot is apparent in most reviews and the soundtrack rules as well (as always). Joe Hisaishi really belongs to Uematsu, Kanno, Williams caliber.People who can brings a movie, a game, an event to life, even to be a lingering moments by astounding composition.<br /><br />This is a feel good movie that used to be part of US cinema in the classic days (It's a Wonderful Life etc etc). Well, things change....\r\n",
            "1\t\"Linking story: another first-time viewing for me and, again, this is one of the most popular of the Amicus anthologies - and it's easy to see why, though I realize how the film's rather meaningless title could be misleading for some; I certainly fancied director Peter Duffell's choice - DEATH AND THE MAIDEN (which, incidentally, is a classical piece by Schubert that is heard in the film during the Peter Cushing episode) - a great deal more. Though the linking device itself is not all that great, the episodes are all equally compelling and enjoyable. Production values come off as very respectable indeed for the budget Duffell had to work with. The latter infuses the film with a great deal of style which is not so common with this type of film and, frankly, it makes one regret the fact that he wished to distance himself from the genre (though more so as not to be typecast rather than because he felt it was beneath him).<br /><br />Now to the individual stories themselves: <br /><br />\"\"Method For Murder\"\": the opening segment does not offer any real surprises but, to make up for this, it's quietly suspenseful and appropriately creepy at times (Tom Adams' 'fictitious' villain looking like the long-lost brother of Boris Karloff from THE OLD DARK HOUSE [1932]); also, it ends with a satisfactory DIABOLIQUE-type twist, and features a fairly intense role for Denholm Elliott in the lead. That's all we need out of it, really.<br /><br />\"\"Waxworks\"\": for the second story we are introduced to a curiously romantic mood which is quite unusual for this type of film; Peter Cushing and Joss Ackland are both excellent (as well as impeccably dressed) in their roles of two jilted lovers of a woman who continues to obsess them even after such a long time, and whose friendly rivalry can only lead them blindly and inexorably to a fate that is literally worse than death; an ominous hallucination scene with Peter Cushing is quite well done in view of the limited resources at hand, and Ackland's inexplicable inability - or unwillingness - to leave town somewhat recalls the house-trapped aristocrats of Bunuel's THE EXTERMINATING ANGEL (1962).<br /><br />\"\"Sweets To The Sweet\"\": this is perhaps the finest episode of all - with his ambiguous role here, Christopher Lee continues to demonstrate his versatility and he is matched by an understanding Nyree Dawn Porter and the deceptive innocence of Chloe Franks (who appears as Lee's daughter). The film's treatment of the occult here is both subtle and mature, culminating in a powerful and extremely chilling 'curtain'. Trivia Note: Chloe Franks appears as a grown-up in the featurette included on the disc, and when I saw her I felt an immediate familiarity with her face but couldn't quite put my finger on it. Later, on reading her filmography, it was revealed to me that she had played one of the leads in the long-running stage adaptation of Agatha Christie's \"\"The Mousetrap\"\" in London's West End, which my brother and I were fortunate enough to catch while we there on holiday in the Summer of 2002! Needless to say, we had no idea then that she had once created such a delicate - and delicious - portrayal in sheer evil, mainly by virtue of her peculiar look and a devilish smile!! <br /><br />\"\"The Cloak\"\": a wacky but oddly reverent vampire tale (that still manages to debunk many of the myths attached to the subgenre, while inventing some new ones!) which takes in some wonderful digs at exploitation cinema and, at one point, Christopher Lee himself!; Jon Pertwee is marvelous as the campy horror star who gets more than he bargained for when he attempts to bring a measure of authenticity to his work; Ingrid Pitt sends up her image nicely though her role is somewhat subsidiary to the proceedings; Geoffrey Bayldon (made up to look like Ernest Thesiger) also has a memorably quirky bit; the 'silent-cinema' style of the ending was a pretty audacious one to pull on an audience, I suppose - and, while some of the humor comes off as heavy-handed a' la THE FEARLESS VAMPIRE KILLERS (1967) or THEATRE OF BLOOD (1973), it's also rather infectious and certainly ends the film on a high (and highly unusual) note! <br /><br />Video and audio quality are relatively satisfactory, considering I had no other version to compare it with; the main culprit is some noticeable print damage but this is never so nasty as to affect one's enjoyment of the film. As for the extras, beginning with the Audio Commentary: frankly, this is one of the finest chats about a genre film that I can remember listening to; Jonathan Rigby gets to butt in with his opinion more than is usual for a moderator but his effort certainly allows director Peter Duffell to touch on every aspect of the production (whereas with some other films, you're left rather expecting there to be more!) and, as such, it's an extremely pleasant track that complements the main feature very nicely indeed. The featurette \"\"A-Rated Horror Film\"\" is a worthwhile effort with Peter Duffell again at center-stage but this time backed up with valid, if all-too-brief, contributions from producer Max J. Rosenberg and stars Chloe Franks, Ingrid Pitt and Geoffrey Bayldon. We also get film notes, reviews, bios and a poster/stills gallery which, again, are wonderfully assembled (with the contemporary reviews being something of a novelty - and a welcome one at that).\"\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDhIYYtaWnAJ",
        "colab_type": "code",
        "outputId": "94f51635-7a9a-4f04-a4a7-bd29da6b72bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Read in the files and quickly print the size of the training and test set.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\")\n",
        "\n",
        "print('Train size = {}'.format(len(train_df)))\n",
        "print('Test size = {}'.format(len(test_df)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 25000\n",
            "Test size = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ZY5sfUxpsv",
        "colab_type": "code",
        "outputId": "fc03a03f-f16a-4605-c25f-cbfbb78e114b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# some prep work so we don't have to wait all the time\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import multiprocessing\n",
        "p = multiprocessing.Pool()\n",
        "\n",
        "train_df_review_tok = p.map(word_tokenize, train_df.review)\n",
        "test_df_review_tok = p.map(word_tokenize, test_df.review)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLEEFkQAQtV",
        "colab_type": "code",
        "outputId": "472b9e31-1646-495c-967a-d34acbbd2770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# preload the word-vectors to make things faster later on\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "model_gensim_glove = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[================================================--] 96.8% 364.1/376.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxVVAh3ks0pn",
        "colab_type": "text"
      },
      "source": [
        "The dataset is from the IMDB review database and contains 50k reviews. As outcome variable we use a simple binary \"is positive\" measure.\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/p6itk8lbh5yoki3/imdb.jpg?dl=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU3gFYvxWpx2",
        "colab_type": "code",
        "outputId": "399c6c2a-8b01-406e-b135-4a462f9b7a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# some basic text cleaning, removing HTML fragments\n",
        "\n",
        "import re\n",
        "\n",
        "pattern = re.compile('<br /><br />')\n",
        "\n",
        "print(train_df['review'].iloc[3])\n",
        "print(pattern.subn(' ', train_df['review'].iloc[3])[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spoilers ahead if you want to call them that...<br /><br />I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...<br /><br />THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\".<br /><br />THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.<br /><br />THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...<br /><br />THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.<br /><br />TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.<br /><br />Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.<br /><br />Signing off... Amanda Christmas\n",
            "Spoilers ahead if you want to call them that... I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top... THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\". THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself. THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards... THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone. TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it. Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it. Signing off... Amanda Christmas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYaG0gtJXBFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# application of the cleaning mask\n",
        "\n",
        "train_df['review'] = train_df['review'].apply(lambda text: pattern.subn(' ', text)[0])\n",
        "test_df['review'] = test_df['review'].apply(lambda text: pattern.subn(' ', text)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0uAoTcXXPO7",
        "colab_type": "text"
      },
      "source": [
        "## Bag of words\n",
        "\n",
        "The most simple way to represent text is by using a so called bag-of-words approach. Here we simply count up words in phrases to represent and build a table of phrases (rows) and words (columns)\n",
        "\n",
        "![bow](https://raw.githubusercontent.com/DanAnastasyev/DeepNLP-Course/master/Week%2001/Images/BOW.png)\n",
        "\n",
        "In python we can do something like that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7dgvR7qXPmv",
        "colab_type": "code",
        "outputId": "90783bd2-470a-4c21-c29c-3d42b45652fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was awful']\n",
        "\n",
        "dummy_matrix = vectorizer.fit_transform(dummy_data)\n",
        "\n",
        "\n",
        "pd.DataFrame(data = dummy_matrix.toarray(), columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awful</th>\n",
              "      <th>excellent</th>\n",
              "      <th>movie</th>\n",
              "      <th>the</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   awful  excellent  movie  the  was\n",
              "0      0          1      1    1    1\n",
              "1      1          0      1    1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuZ3OcxDXTpA",
        "colab_type": "code",
        "outputId": "588860df-49aa-4604-cff2-b5ab94c10eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Let's apply this method to the entire training dataset (50%)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(train_df['review'].values)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLejCrdstYg",
        "colab_type": "code",
        "outputId": "4cd9476c-a4b9-469c-98dc-0b1b9d1185ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Some simple statistics and illustration\n",
        "\n",
        "print(vectorizer.get_feature_names()[:20])\n",
        "print(vectorizer.get_feature_names()[-20:])\n",
        "print(len(vectorizer.get_feature_names()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
            "['är', 'ääliöt', 'äänekoski', 'åge', 'åmål', 'æsthetic', 'écran', 'élan', 'émigré', 'émigrés', 'était', 'état', 'étc', 'évery', 'êxtase', 'ís', 'ísnt', 'østbye', 'über', 'üvegtigris']\n",
            "74849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5kaSokuV3P",
        "colab_type": "text"
      },
      "source": [
        "In Python's SKlearn toolkit most models (and preprocessing) use a fit-transform logic\n",
        "- `fit` here means \"go learn all words and build an index\n",
        "- `transform` generates the transformation in a 2nd step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-maapdnzs0AV",
        "colab_type": "code",
        "outputId": "3dba98da-f763-483d-f29d-9923f6eb7b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# let's apply the fitted vectorizer to one review\n",
        "\n",
        "vectorizer.transform([train_df['review'].iloc[3]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 206 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJogMC7uwNk",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we obtain as output a sparse matrix of shape (1, 75k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeV05EGDtVPj",
        "colab_type": "text"
      },
      "source": [
        "The task is to build a classifier that sorts reviews automatically into positive or negative. Intuitively, if we needed to create some program, we would to somthing like this:\n",
        "\n",
        "We would give positive words a value, let's say 1; negative words -1, and 0s for all neutral\n",
        "\n",
        "The simples way of learning such a linear model is using a logistic regression. Let's try that.\n",
        "\n",
        "![bow with weights](https://github.com/DanAnastasyev/DeepNLP-Course/raw/master/Week%2001/Images/BOW_weights.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7luA_DbitVmr",
        "colab_type": "code",
        "outputId": "6db6ff52-f141-485d-ce45-af6b6ba3078f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# to make things more elegant, we use a pipeline here\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was awful']\n",
        "\n",
        "dummy_labels = [1, 0]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(dummy_data, dummy_labels)\n",
        "\n",
        "\n",
        "pd.DataFrame(data = classifier.coef_, columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awful</th>\n",
              "      <th>excellent</th>\n",
              "      <th>movie</th>\n",
              "      <th>the</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.401058</td>\n",
              "      <td>0.401058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      awful  excellent  movie  the  was\n",
              "0 -0.401058   0.401058    0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ludMj0xYv0eD",
        "colab_type": "text"
      },
      "source": [
        "As we expected, the model learned that \"awful\" is something bad while \"excellent\" is something good.\n",
        "We can now do the same for the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rro5dHYMtcuf",
        "colab_type": "code",
        "outputId": "7ab1e6ab-f6f0-4fdd-8636-0eaec6fae85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# note, that model here refers to the whole pipeline, not only the logistic regression classifier.\n",
        "\n",
        "model.fit(train_df['review'], train_df['is_positive'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='warn', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='warn', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAoXn7gVtopO",
        "colab_type": "code",
        "outputId": "f99a3ce7-6d5b-40c4-e801-91f7aa92253b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we can also evaluate the performance\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def eval_model(model, test_df):\n",
        "    preds = model.predict(test_df['review'])\n",
        "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))\n",
        "    \n",
        "eval_model(model, test_df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy = 86.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hEYan95xE50",
        "colab_type": "text"
      },
      "source": [
        "In recent years there has been much focus on model explainability\n",
        "\n",
        "![alt text](https://media.giphy.com/media/9FvN85CcQU9fW/giphy.gif)\n",
        "\n",
        "The community developed some nice models and tools to understand ML results\n",
        "one of them is LIME  (https://arxiv.org/abs/1602.04938) which is implemented in **eli5**  with a focus on text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OezBnslZupXg",
        "colab_type": "code",
        "outputId": "06fc4e0f-b837-4164-e387-ea82fe481d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "# first we can check the weights\n",
        "\n",
        "import eli5\n",
        "eli5.show_weights(classifier, vec=vectorizer, top=30)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.585\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        refreshing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.10%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.411\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wonderfully\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.52%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.354\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        erotic\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.296\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        funniest\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.02%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.288\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        perfect\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.282\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        excellent\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.09%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.279\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        carrey\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.23%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.261\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        superb\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.250\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        surprisingly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.250\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        appreciated\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.31%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 37579 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.39%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 37241 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.39%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.240\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        unwatchable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.27%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.255\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        weak\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.26%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.256\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        forgettable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.13%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.274\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worse\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.03%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.287\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        baldwin\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.57%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.347\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        avoid\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.56%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.349\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        horrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.47%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.360\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        britney\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.99%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.425\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        fails\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.429\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        laughable\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.69%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.467\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.58%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.482\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        unfunny\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.12%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.545\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        mess\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.546\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        boring\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.93%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.713\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        awful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.79%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.733\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        lacks\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.14%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.828\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poorly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.25%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.110\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointment\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.120\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        waste\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.148\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worst\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Zfx8qEuv6n",
        "colab_type": "code",
        "outputId": "86a63682-039f-40cb-986a-c5f6e4d86d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "# we can repeat the exercise for a specific prediction\n",
        "\n",
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>1.000</b>, score <b>16.248</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +16.203\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.045\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 97.40%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.25%); opacity: 0.87\" title=\"0.334\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.07%); opacity: 0.81\" title=\"-0.049\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.11%); opacity: 0.95\" title=\"0.745\">entertaining</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.985\">touching</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.02%); opacity: 0.81\" title=\"-0.050\">version</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.15%); opacity: 0.88\" title=\"0.415\">classic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.85%); opacity: 0.85\" title=\"0.223\">tale</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 85.96%); opacity: 0.84\" title=\"0.221\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.66%); opacity: 0.84\" title=\"0.205\">quite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.84%); opacity: 0.85\" title=\"0.270\">intelligent</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.202\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 99.67%); opacity: 0.80\" title=\"-0.001\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 87.35%); opacity: 0.84\" title=\"0.190\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.99%); opacity: 0.82\" title=\"0.099\">jane</span><span style=\"opacity: 0.80\">&#x27; </span><span style=\"background-color: hsl(120, 100.00%, 93.60%); opacity: 0.81\" title=\"0.072\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.26%); opacity: 0.80\" title=\"-0.011\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.46%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.53%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.03%); opacity: 0.85\" title=\"0.265\">famous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.66%); opacity: 0.81\" title=\"0.041\">story</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 95.46%); opacity: 0.81\" title=\"-0.044\">child</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.18%); opacity: 0.81\" title=\"-0.063\">reared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.90%); opacity: 0.85\" title=\"0.245\">manhood</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.077\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.24%); opacity: 0.80\" title=\"-0.003\">apes</span><span style=\"opacity: 0.80\">. a </span><span style=\"background-color: hsl(0, 100.00%, 83.47%); opacity: 0.86\" title=\"-0.279\">titled</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.92%); opacity: 0.82\" title=\"0.083\">british</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.99%); opacity: 0.84\" title=\"-0.198\">couple</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.71%); opacity: 0.81\" title=\"0.070\">wife</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.68%); opacity: 0.87\" title=\"-0.323\">pregnant</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.89%); opacity: 0.80\" title=\"0.015\">stranded</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.63%); opacity: 0.82\" title=\"0.105\">african</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.79%); opacity: 0.81\" title=\"-0.069\">wilds</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.032\">after</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 99.88%); opacity: 0.80\" title=\"-0.000\">shipwreck</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.032\">after</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.91%); opacity: 0.90\" title=\"0.506\">parents</span><span style=\"opacity: 0.80\">&#x27; </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.158\">deaths</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.88%); opacity: 0.85\" title=\"-0.223\">baby</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.142\">raised</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.077\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.24%); opacity: 0.80\" title=\"-0.003\">apes</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 81.21%); opacity: 0.87\" title=\"0.335\">twenty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.79%); opacity: 0.81\" title=\"0.069\">years</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.88%); opacity: 0.86\" title=\"0.318\">later</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.40%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.36%); opacity: 0.81\" title=\"-0.045\">young</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.78%); opacity: 0.81\" title=\"0.040\">man</span><span style=\"opacity: 0.80\"> (i.e. </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 91.18%); opacity: 0.82\" title=\"-0.114\">rescues</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 95.92%); opacity: 0.81\" title=\"-0.038\">wounded</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.44%); opacity: 0.83\" title=\"-0.127\">belgian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.71%); opacity: 0.80\" title=\"0.007\">explorer</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.63%); opacity: 0.81\" title=\"0.071\">nursing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.46%); opacity: 0.83\" title=\"0.147\">him</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.79%); opacity: 0.81\" title=\"-0.039\">back</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.21%); opacity: 0.81\" title=\"-0.047\">health</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.44%); opacity: 0.83\" title=\"-0.127\">belgian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.67%); opacity: 0.91\" title=\"0.542\">discovers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.70%); opacity: 0.81\" title=\"0.055\">evidence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.87%); opacity: 0.80\" title=\"-0.015\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.92%); opacity: 0.81\" title=\"0.052\">rescuer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.36%); opacity: 0.81\" title=\"-0.045\">young</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.78%); opacity: 0.81\" title=\"-0.040\">lord</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.29%); opacity: 0.80\" title=\"-0.003\">greystoke</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.23%); opacity: 0.86\" title=\"0.284\">returns</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.46%); opacity: 0.83\" title=\"0.147\">him</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.01%); opacity: 0.81\" title=\"-0.065\">rightful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.12%); opacity: 0.85\" title=\"-0.263\">estate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.32%); opacity: 0.84\" title=\"-0.213\">scotland</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 94.24%); opacity: 0.81\" title=\"-0.062\">where</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.019\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.15%); opacity: 0.86\" title=\"0.311\">must</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.60%); opacity: 0.80\" title=\"0.001\">adjust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.61%); opacity: 0.80\" title=\"-0.008\">civilized</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.94%); opacity: 0.82\" title=\"0.118\">society</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.10%); opacity: 0.80\" title=\"0.023\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.86%); opacity: 0.83\" title=\"-0.159\">sort</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.26%); opacity: 0.84\" title=\"0.214\">divided</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.93%); opacity: 0.81\" title=\"0.052\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.99%); opacity: 0.81\" title=\"0.037\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.02%); opacity: 0.83\" title=\"0.155\">parts</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.43%); opacity: 0.83\" title=\"0.147\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.01%); opacity: 0.87\" title=\"-0.340\">half</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.31%); opacity: 0.81\" title=\"0.046\">we</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.05%); opacity: 0.84\" title=\"0.175\">see</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.38%); opacity: 0.87\" title=\"-0.330\">environment</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.202\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.35%); opacity: 0.80\" title=\"0.010\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.07%); opacity: 0.81\" title=\"-0.049\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.97%); opacity: 0.83\" title=\"0.137\">expert</span><span style=\"opacity: 0.80\">, i </span><span style=\"background-color: hsl(0, 100.00%, 81.36%); opacity: 0.87\" title=\"-0.331\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.04%); opacity: 0.85\" title=\"0.265\">unaware</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.027\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.84%); opacity: 0.90\" title=\"0.508\">realism</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.070\">its</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.76%); opacity: 0.84\" title=\"0.203\">depiction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.59%); opacity: 0.84\" title=\"-0.185\">ape</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.49%); opacity: 0.88\" title=\"0.379\">community</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.60%); opacity: 0.85\" title=\"0.229\">life</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.56%); opacity: 0.81\" title=\"-0.043\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.53%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.97%); opacity: 0.82\" title=\"0.099\">certainly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.11%); opacity: 0.95\" title=\"0.745\">entertaining</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 96.24%); opacity: 0.81\" title=\"-0.034\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.67%); opacity: 0.80\" title=\"-0.001\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.84%); opacity: 0.82\" title=\"0.120\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.89%); opacity: 0.94\" title=\"0.688\">moving</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.115\">section</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.37%); opacity: 0.81\" title=\"-0.045\">second</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.01%); opacity: 0.87\" title=\"-0.340\">half</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 98.77%); opacity: 0.80\" title=\"-0.007\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.15%); opacity: 0.86\" title=\"0.311\">must</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.57%); opacity: 0.83\" title=\"-0.165\">meet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.85%); opacity: 0.84\" title=\"0.201\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.92%); opacity: 0.85\" title=\"0.268\">family</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.03%); opacity: 0.80\" title=\"-0.024\">develop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.73%); opacity: 0.89\" title=\"0.427\">language</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.88%); opacity: 0.84\" title=\"-0.200\">skills</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.60%); opacity: 0.80\" title=\"0.001\">adjust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.86%); opacity: 0.80\" title=\"-0.006\">aristocratic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.92%); opacity: 0.82\" title=\"0.083\">british</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.94%); opacity: 0.82\" title=\"0.118\">society</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.46%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.93%); opacity: 0.82\" title=\"0.100\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.66%); opacity: 0.81\" title=\"-0.041\">wooing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.99%); opacity: 0.82\" title=\"0.099\">jane</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 90.10%); opacity: 0.83\" title=\"0.134\">andie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.057\">macdowell</span><span style=\"opacity: 0.80\">). </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.019\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.27%); opacity: 0.86\" title=\"-0.308\">portrayed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.027\">as</span><span style=\"opacity: 0.80\"> a &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.020\">noble</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.02%); opacity: 0.91\" title=\"0.532\">savage</span><span style=\"opacity: 0.80\">&#x27;, </span><span style=\"background-color: hsl(0, 100.00%, 83.26%); opacity: 0.86\" title=\"-0.284\">whether</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.115\">wild</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.61%); opacity: 0.80\" title=\"-0.018\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.05%); opacity: 0.85\" title=\"0.241\">elegant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.011\">edwardian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.41%); opacity: 0.84\" title=\"-0.211\">parlors</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.077\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.33%); opacity: 0.91\" title=\"0.552\">contrast</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.90%); opacity: 0.82\" title=\"-0.101\">upper</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.63%); opacity: 0.81\" title=\"-0.042\">crust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.87%); opacity: 0.95\" title=\"-0.720\">depicted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.027\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.35%); opacity: 0.86\" title=\"0.282\">often</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.13%); opacity: 0.86\" title=\"-0.287\">far</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.84%); opacity: 0.82\" title=\"0.120\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">barbaric</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.52%); opacity: 0.80\" title=\"0.009\">than</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.72%); opacity: 0.88\" title=\"-0.373\">left</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 83.05%); opacity: 0.86\" title=\"-0.289\">christopher</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.35%); opacity: 0.81\" title=\"0.032\">lambert</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.91%); opacity: 0.94\" title=\"0.687\">fantastic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.14%); opacity: 0.94\" title=\"0.680\">sympathetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.22%); opacity: 0.86\" title=\"0.309\">portrayal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.25%); opacity: 0.87\" title=\"0.334\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.61%); opacity: 0.80\" title=\"-0.008\">civilized</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.55%); opacity: 0.82\" title=\"-0.107\">environments</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.019\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.83%); opacity: 0.85\" title=\"0.224\">conveys</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 86.85%); opacity: 0.84\" title=\"0.201\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.06%); opacity: 0.82\" title=\"-0.081\">sense</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.52%); opacity: 0.81\" title=\"0.073\">confusion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.62%); opacity: 0.87\" title=\"-0.324\">conflict</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 78.76%); opacity: 0.88\" title=\"0.399\">torn</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.027\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.019\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.24%); opacity: 0.82\" title=\"-0.095\">between</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.99%); opacity: 0.81\" title=\"0.037\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.41%); opacity: 0.83\" title=\"0.128\">very</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.41%); opacity: 0.83\" title=\"0.147\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.06%); opacity: 0.93\" title=\"0.651\">worlds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.27%); opacity: 0.85\" title=\"-0.260\">original</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.59%); opacity: 0.84\" title=\"-0.185\">ape</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.92%); opacity: 0.85\" title=\"0.268\">family</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.31%); opacity: 0.81\" title=\"0.046\">new</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.80%); opacity: 0.86\" title=\"0.320\">human</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.22%); opacity: 0.82\" title=\"-0.078\">one</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 86.21%); opacity: 0.84\" title=\"0.215\">sir</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.39%); opacity: 0.92\" title=\"0.610\">ralph</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.94%); opacity: 0.82\" title=\"-0.100\">richardson</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.22%); opacity: 0.82\" title=\"-0.078\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.67%); opacity: 0.80\" title=\"-0.001\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.92%); opacity: 0.82\" title=\"0.083\">british</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.96%); opacity: 0.91\" title=\"-0.533\">legends</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.88%); opacity: 0.99\" title=\"0.920\">brilliant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.027\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.77%); opacity: 0.86\" title=\"0.296\">always</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.26%); opacity: 0.81\" title=\"-0.061\">role</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(0, 100.00%, 89.66%); opacity: 0.83\" title=\"-0.143\">grandfather</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.10%); opacity: 0.83\" title=\"-0.134\">sixth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.64%); opacity: 0.82\" title=\"0.105\">earl</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.29%); opacity: 0.80\" title=\"-0.003\">greystoke</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.49%); opacity: 0.82\" title=\"0.090\">film</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.16%); opacity: 0.93\" title=\"0.617\">focuses</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.84%); opacity: 0.82\" title=\"0.120\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.028\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.106\">tarzan</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(0, 100.00%, 81.15%); opacity: 0.87\" title=\"-0.336\">struggles</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.17%); opacity: 0.84\" title=\"0.194\">adapting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.49%); opacity: 0.81\" title=\"-0.074\">civilization</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.03%); opacity: 0.89\" title=\"-0.446\">inner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.62%); opacity: 0.87\" title=\"-0.324\">conflict</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.52%); opacity: 0.80\" title=\"0.009\">than</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.028\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.38%); opacity: 0.82\" title=\"0.075\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.61%); opacity: 0.86\" title=\"-0.275\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.54%); opacity: 0.86\" title=\"-0.301\">exploits</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 97.40%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.94%); opacity: 0.81\" title=\"0.051\">unusual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.72%); opacity: 0.84\" title=\"0.204\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.028\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.67%); opacity: 0.80\" title=\"-0.001\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.15%); opacity: 0.88\" title=\"0.415\">classic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.83%); opacity: 0.88\" title=\"0.370\">makes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.53%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.25%); opacity: 0.87\" title=\"0.334\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.28%); opacity: 0.82\" title=\"0.077\">typical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.81%); opacity: 0.81\" title=\"0.068\">dramatic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.88%); opacity: 0.86\" title=\"0.293\">adventure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.56%); opacity: 0.81\" title=\"-0.043\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.96%); opacity: 0.84\" title=\"0.221\">also</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 82.23%); opacity: 0.86\" title=\"0.309\">above</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.46%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\">, a </span><span style=\"background-color: hsl(120, 100.00%, 68.89%); opacity: 0.94\" title=\"0.688\">moving</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.51%); opacity: 0.83\" title=\"-0.166\">personal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.66%); opacity: 0.81\" title=\"0.041\">story</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 89.70%); opacity: 0.83\" title=\"-0.142\">wasn</span><span style=\"opacity: 0.80\">&#x27;t </span><span style=\"background-color: hsl(120, 100.00%, 67.57%); opacity: 0.95\" title=\"0.730\">surprised</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.78%); opacity: 0.87\" title=\"-0.346\">note</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.82%); opacity: 0.85\" title=\"-0.247\">here</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.87%); opacity: 0.80\" title=\"-0.015\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.070\">its</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.80%); opacity: 0.86\" title=\"-0.320\">director</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.42%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.08%); opacity: 0.82\" title=\"-0.097\">same</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.74%); opacity: 0.81\" title=\"0.040\">individual</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.23%); opacity: 0.82\" title=\"0.078\">hugh</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.36%); opacity: 0.80\" title=\"0.010\">hudson</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 89.94%); opacity: 0.83\" title=\"0.137\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.96%); opacity: 0.84\" title=\"0.221\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.60%); opacity: 0.89\" title=\"-0.430\">directed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.55%); opacity: 0.81\" title=\"-0.030\">chariots</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.95%); opacity: 0.82\" title=\"-0.118\">fire</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 94.90%); opacity: 0.81\" title=\"-0.052\">another</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.88%); opacity: 0.99\" title=\"0.920\">brilliant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.10%); opacity: 0.80\" title=\"0.023\">movie</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uazTdjThvDk3",
        "colab_type": "code",
        "outputId": "4b7eb8ef-db5c-440a-ad68-ceab18be8a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[12] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[12], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.017</b>, score <b>-4.078</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.045\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.122\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.81%); opacity: 0.83\" title=\"0.160\">episode</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.59%); opacity: 0.90\" title=\"-0.517\">sucks</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 97.07%); opacity: 0.80\" title=\"-0.024\">over</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.036\">past</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.42%); opacity: 0.81\" title=\"-0.045\">few</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.80%); opacity: 0.81\" title=\"0.069\">years</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 95.04%); opacity: 0.81\" title=\"-0.050\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.64%); opacity: 0.87\" title=\"-0.325\">watched</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.46%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.85%); opacity: 0.89\" title=\"0.453\">episodes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(0, 100.00%, 94.58%); opacity: 0.81\" title=\"-0.057\">next</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.33%); opacity: 0.80\" title=\"-0.021\">generation</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 92.76%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 87.45%); opacity: 0.84\" title=\"0.189\">voyager</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 92.76%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.40%); opacity: 0.87\" title=\"-0.331\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.47%); opacity: 0.87\" title=\"0.329\">now</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.75%); opacity: 0.82\" title=\"-0.104\">watching</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 85.23%); opacity: 0.85\" title=\"0.238\">enterprise</span><span style=\"opacity: 0.80\">&quot;. i </span><span style=\"background-color: hsl(0, 100.00%, 81.40%); opacity: 0.87\" title=\"-0.331\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.39%); opacity: 0.88\" title=\"0.383\">thoroughly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.45%); opacity: 0.89\" title=\"0.436\">enjoying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.19%); opacity: 0.86\" title=\"0.287\">series</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 92.74%); opacity: 0.82\" title=\"0.086\">until</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.81%); opacity: 0.83\" title=\"0.160\">episode</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 91.38%); opacity: 0.82\" title=\"-0.110\">stared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.26%); opacity: 0.80\" title=\"-0.011\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.097\">screen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.05%); opacity: 0.84\" title=\"-0.197\">horror</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.26%); opacity: 0.80\" title=\"-0.011\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.94%); opacity: 0.84\" title=\"-0.222\">destruction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.065\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.61%); opacity: 0.81\" title=\"0.029\">character</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.76%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.05%); opacity: 0.84\" title=\"0.219\">entertainment</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.86%); opacity: 0.82\" title=\"0.120\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.57%); opacity: 0.80\" title=\"0.018\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.08%); opacity: 0.81\" title=\"-0.049\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.02%); opacity: 0.93\" title=\"-0.655\">attempt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.26%); opacity: 0.80\" title=\"-0.011\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.94%); opacity: 0.84\" title=\"0.200\">slapstick</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.09%); opacity: 0.83\" title=\"-0.135\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.85%); opacity: 0.84\" title=\"-0.202\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.85%); opacity: 0.83\" title=\"-0.159\">build</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.29%); opacity: 0.82\" title=\"-0.094\">characters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.57%); opacity: 0.81\" title=\"-0.043\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.62%); opacity: 0.88\" title=\"-0.377\">throws</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.85%); opacity: 0.81\" title=\"-0.026\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.26%); opacity: 0.81\" title=\"0.033\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.69%); opacity: 0.81\" title=\"-0.028\">on</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 94.73%); opacity: 0.81\" title=\"-0.055\">limb</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 92.76%); opacity: 0.82\" title=\"0.086\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.20%); opacity: 0.82\" title=\"0.114\">leaves</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.77%); opacity: 0.80\" title=\"-0.001\">audience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.16%); opacity: 0.82\" title=\"0.096\">gasping</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.09%); opacity: 0.83\" title=\"-0.135\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.16%); opacity: 0.80\" title=\"0.012\">little</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.85%); opacity: 0.83\" title=\"-0.159\">build</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.19%); opacity: 0.86\" title=\"0.287\">series</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 86.28%); opacity: 0.84\" title=\"-0.214\">why</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.066\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.83%); opacity: 0.82\" title=\"0.085\">ever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.94%); opacity: 0.84\" title=\"-0.200\">allowed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.56%); opacity: 0.81\" title=\"0.057\">go</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.008\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.21%); opacity: 0.85\" title=\"-0.262\">air</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.88%); opacity: 0.86\" title=\"-0.294\">amazes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.67%); opacity: 0.80\" title=\"-0.001\">me</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.066\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.18%); opacity: 0.90\" title=\"-0.471\">writing</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.066\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.21%); opacity: 0.83\" title=\"-0.152\">directing</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.066\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.45%); opacity: 0.84\" title=\"0.210\">producer</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(120, 100.00%, 95.32%); opacity: 0.81\" title=\"0.046\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 91.74%); opacity: 0.82\" title=\"-0.104\">ll</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.61%); opacity: 0.82\" title=\"-0.089\">probably</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.46%); opacity: 0.81\" title=\"0.031\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.16%); opacity: 0.82\" title=\"0.096\">know</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 95.57%); opacity: 0.81\" title=\"-0.043\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.24%); opacity: 0.82\" title=\"-0.078\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.37%); opacity: 0.94\" title=\"-0.707\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.11%); opacity: 0.85\" title=\"-0.264\">apple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.82%); opacity: 0.81\" title=\"-0.039\">isn</span><span style=\"opacity: 0.80\">&#x27;t </span><span style=\"background-color: hsl(0, 100.00%, 68.37%); opacity: 0.94\" title=\"-0.707\">bad</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 88.04%); opacity: 0.84\" title=\"-0.176\">suppose</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 96.03%); opacity: 0.81\" title=\"-0.036\">say</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.87%); opacity: 0.80\" title=\"-0.015\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.988\">hoping</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.55%); opacity: 0.83\" title=\"0.126\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.040\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.66%); opacity: 0.84\" title=\"-0.184\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.24%); opacity: 0.82\" title=\"-0.078\">one</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq_iy8Ha2eAl",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "Right now we attribute equal weight to all words - yet, some are more rare, others more prominent; and this frequency of occurence is actually useful information.\n",
        "\n",
        "The easiest approach to add statistical information on frequency is to apply *tf-idf* weights:\n",
        "\n",
        "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) \\times \\text{idf}(t)$$\n",
        "\n",
        "*tf* - term-frequency - `t` in the specific document `d` (in our case the individual review). This is exactly what we were doing before.\n",
        "\n",
        "*idf* - inverse document-frequency - coefficient which is larger whenever the particular term is found in a lesser number of documents. We calculate it like so:\n",
        "$$\\text{idf}(t) = \\text{log}\\frac{1 + n_d}{1 + n_{d(t)}} + 1$$\n",
        "where $n_d$ - the number of all documents and $n_{d(t)}$ - the number of documents containing the word `t`.\n",
        "\n",
        "It's very easy to use - just replace `CountVectorizer` with `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkwu0FmEO0rg",
        "colab_type": "code",
        "outputId": "0b4b5e40-5440-4e52-e66d-7d8918fcc654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# To implement TF-IDF we only need to replace the vectorizer \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was awful']\n",
        "\n",
        "dummy_labels = [1, 0]\n",
        "\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(dummy_data, dummy_labels)\n",
        "\n",
        "\n",
        "pd.DataFrame(data = classifier.coef_, columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awful</th>\n",
              "      <th>excellent</th>\n",
              "      <th>movie</th>\n",
              "      <th>the</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.286673</td>\n",
              "      <td>0.286673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      awful  excellent  movie  the  was\n",
              "0 -0.286673   0.286673    0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGeXwTW9vdsN",
        "colab_type": "code",
        "outputId": "5f0c51a0-405b-4736-c4cd-4975284f9d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['review'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy = 88.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRsw0GA3wb3j",
        "colab_type": "code",
        "outputId": "5436c59a-9395-4062-9ec1-da648ce97f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[12] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[12], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.217</b>, score <b>-1.284</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.01%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.155\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.129\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.029\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.21%); opacity: 0.85\" title=\"0.120\">episode</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.17%); opacity: 0.88\" title=\"-0.191\">sucks</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 90.81%); opacity: 0.82\" title=\"-0.056\">over</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.69%); opacity: 0.82\" title=\"0.057\">past</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.027\">few</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.99%); opacity: 0.85\" title=\"0.112\">years</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 92.31%); opacity: 0.82\" title=\"-0.043\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.96%); opacity: 0.81\" title=\"-0.031\">watched</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.12%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.74%); opacity: 0.88\" title=\"0.184\">episodes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.92%); opacity: 0.80\" title=\"-0.000\">of</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 95.43%); opacity: 0.81\" title=\"0.020\">next</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.66%); opacity: 0.80\" title=\"-0.004\">generation</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.077\">and</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 89.10%); opacity: 0.83\" title=\"0.071\">voyager</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.077\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.13%); opacity: 0.85\" title=\"-0.110\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.75%); opacity: 0.83\" title=\"0.074\">now</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.57%); opacity: 0.83\" title=\"-0.076\">watching</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 89.86%); opacity: 0.83\" title=\"0.064\">enterprise</span><span style=\"opacity: 0.80\">&quot;. i </span><span style=\"background-color: hsl(0, 100.00%, 85.13%); opacity: 0.85\" title=\"-0.110\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.05%); opacity: 0.83\" title=\"0.071\">thoroughly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.57%); opacity: 0.83\" title=\"0.076\">enjoying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.029\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.85%); opacity: 0.87\" title=\"0.159\">series</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.050\">until</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.029\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.21%); opacity: 0.85\" title=\"0.120\">episode</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 94.12%); opacity: 0.81\" title=\"-0.029\">stared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.99%); opacity: 0.81\" title=\"-0.030\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.40%); opacity: 0.80\" title=\"0.005\">screen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.52%); opacity: 0.81\" title=\"0.014\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.08%); opacity: 0.83\" title=\"-0.071\">horror</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.99%); opacity: 0.81\" title=\"-0.030\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.20%); opacity: 0.80\" title=\"0.002\">destruction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.92%); opacity: 0.80\" title=\"-0.000\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.37%); opacity: 0.81\" title=\"-0.028\">character</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.077\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.21%); opacity: 0.83\" title=\"0.061\">entertainment</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.00%); opacity: 0.82\" title=\"0.038\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.27%); opacity: 0.83\" title=\"0.069\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.030\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.94%); opacity: 0.81\" title=\"-0.017\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.96%); opacity: 0.91\" title=\"-0.260\">attempt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.99%); opacity: 0.81\" title=\"-0.030\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.07%); opacity: 0.81\" title=\"0.023\">slapstick</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.64%); opacity: 0.81\" title=\"-0.033\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.37%); opacity: 0.84\" title=\"-0.088\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.70%); opacity: 0.81\" title=\"-0.013\">build</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.34%); opacity: 0.82\" title=\"-0.035\">characters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.84%); opacity: 0.81\" title=\"-0.024\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.89%); opacity: 0.84\" title=\"-0.082\">throws</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.36%); opacity: 0.81\" title=\"-0.015\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.65%); opacity: 0.81\" title=\"-0.013\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.99%); opacity: 0.81\" title=\"-0.023\">on</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 97.07%); opacity: 0.80\" title=\"-0.011\">limb</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.077\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.05%); opacity: 0.81\" title=\"0.023\">leaves</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.66%); opacity: 0.82\" title=\"-0.040\">audience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.58%); opacity: 0.81\" title=\"0.014\">gasping</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.64%); opacity: 0.81\" title=\"-0.033\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.031\">little</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.031\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.70%); opacity: 0.81\" title=\"-0.013\">build</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.85%); opacity: 0.87\" title=\"0.159\">series</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 80.05%); opacity: 0.87\" title=\"-0.168\">why</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.029\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.17%); opacity: 0.82\" title=\"-0.052\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.03%); opacity: 0.80\" title=\"0.011\">ever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.59%); opacity: 0.81\" title=\"-0.033\">allowed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.031\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.05%); opacity: 0.80\" title=\"-0.002\">go</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.031\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.60%); opacity: 0.83\" title=\"-0.057\">air</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.14%); opacity: 0.82\" title=\"-0.044\">amazes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.64%); opacity: 0.81\" title=\"0.026\">me</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 91.17%); opacity: 0.82\" title=\"-0.052\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.24%); opacity: 0.85\" title=\"-0.120\">writing</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(0, 100.00%, 91.17%); opacity: 0.82\" title=\"-0.052\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.31%); opacity: 0.81\" title=\"-0.028\">directing</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(0, 100.00%, 91.17%); opacity: 0.82\" title=\"-0.052\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.83%); opacity: 0.80\" title=\"0.007\">producer</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(120, 100.00%, 96.10%); opacity: 0.81\" title=\"0.016\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 93.72%); opacity: 0.81\" title=\"-0.032\">ll</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.013\">probably</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.012\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.58%); opacity: 0.83\" title=\"0.058\">know</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 94.84%); opacity: 0.81\" title=\"-0.024\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.78%); opacity: 0.80\" title=\"0.003\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.454\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.20%); opacity: 0.81\" title=\"-0.022\">apple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.66%); opacity: 0.83\" title=\"-0.075\">isn</span><span style=\"opacity: 0.80\">&#x27;t </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.454\">bad</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 85.61%); opacity: 0.85\" title=\"-0.105\">suppose</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 98.28%); opacity: 0.80\" title=\"-0.005\">say</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.20%); opacity: 0.80\" title=\"-0.010\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.44%); opacity: 0.89\" title=\"-0.200\">hoping</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.086\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.00%); opacity: 0.82\" title=\"0.038\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.31%); opacity: 0.86\" title=\"-0.142\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.78%); opacity: 0.80\" title=\"0.003\">one</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm18-bwt3ocd",
        "colab_type": "text"
      },
      "source": [
        "## Topic modelling & more complex models\n",
        "\n",
        "\n",
        "While >88% is a great result, we can try to further improve it by applying more complex methods. For instance, we can try to reduce the dimensionality of the input matrix. One way to achieve it is topic modelling. The illustration is more suited to explain LDA (latent Dirichlet allocation) but can also be used to understand other related approaches. We will be using Latent Semantic Analysis (LSA).\n",
        "In a nutshell, we will transform the matrix (representing the phrases) into a matrix of lower dimensionality where each dimension is an (optimally) interpretable combination of overall co-occuring terms and thereby a topic. A phrase is then a combination of various topics rather than a combination of terms.\n",
        "\n",
        "A very easy way of implementing LSA is using SKLean's truncated SVD module (truncated singular value decomposition) - which is exactly the same as LSA. Why 2 names? Because different communities call their things differently.\n",
        "\n",
        "We will also use a different classifier. Just to make a point that often it doesn't matter...or does it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xxe9wysPXbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# we will use Extreme Gradient Boosting (XGBoost) for the classification\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "vec = TfidfVectorizer()\n",
        "svd = TruncatedSVD(n_components=200, n_iter=7, random_state=42)\n",
        "\n",
        "lsa = make_pipeline(vec, svd)\n",
        "\n",
        "clf = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
        "\n",
        "pipe = make_pipeline(lsa, clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuTTuUALG1qV",
        "colab_type": "code",
        "outputId": "10e82317-9246-4e0c-ddcc-a0156dc64597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "pipe.fit(train_df['review'], train_df['is_positive'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('pipeline',\n",
              "                 Pipeline(memory=None,\n",
              "                          steps=[('tfidfvectorizer',\n",
              "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                                  decode_error='strict',\n",
              "                                                  dtype=<class 'numpy.float64'>,\n",
              "                                                  encoding='utf-8',\n",
              "                                                  input='content',\n",
              "                                                  lowercase=True, max_df=1.0,\n",
              "                                                  max_features=None, min_df=1,\n",
              "                                                  ngram_range=(1, 1), norm='l2',\n",
              "                                                  preprocessor=None,\n",
              "                                                  smooth_idf=True,\n",
              "                                                  stop_words=None,\n",
              "                                                  str...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=300, n_jobs=1, nthread=None,\n",
              "                               objective='binary:logistic', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozmiCU_ePk12",
        "colab_type": "code",
        "outputId": "e3ad5c99-9893-4499-8fee-5893d728e161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pipe.score(test_df.review, test_df['is_positive'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEu6ayx96kSh",
        "colab_type": "text"
      },
      "source": [
        "In the former examples life was rather easy when looking at explainability. With LSA and XGBoost we are in a situation where we are dealing with a black-box model. Here again **eli5** as a wrapper around **LIME** is helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgzxNc5sT71Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from eli5.lime import TextExplainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwWqtExjH8S2",
        "colab_type": "code",
        "outputId": "035d547a-0a7e-41a7-c909-fa107268eeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "te = TextExplainer(random_state=42)\n",
        "te.fit(test_df.review[1], pipe.predict_proba)\n",
        "te.show_prediction(target_names=['negative', 'positive'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=positive\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.880</b>, score <b>1.992</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.005\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 99.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.013\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 90.44%); opacity: 0.83\" title=\"0.033\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.05%); opacity: 0.87\" title=\"0.088\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.47%); opacity: 0.82\" title=\"-0.019\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.87%); opacity: 0.82\" title=\"-0.026\">entertaining</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.49%); opacity: 0.86\" title=\"0.072\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.08%); opacity: 0.91\" title=\"0.137\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.24%); opacity: 0.96\" title=\"0.200\">touching</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.31%); opacity: 0.83\" title=\"0.034\">version</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.95%); opacity: 0.81\" title=\"-0.013\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.31%); opacity: 0.81\" title=\"-0.016\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.81%); opacity: 0.87\" title=\"0.089\">classic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.68%); opacity: 0.89\" title=\"-0.118\">tale</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 85.74%); opacity: 0.85\" title=\"0.058\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.31%); opacity: 0.91\" title=\"0.136\">quite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.15%); opacity: 0.89\" title=\"0.115\">intelligent</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 89.77%); opacity: 0.83\" title=\"0.036\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.95%); opacity: 0.81\" title=\"-0.013\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.31%); opacity: 0.81\" title=\"-0.016\">the</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 82.75%); opacity: 0.86\" title=\"0.077\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.94%); opacity: 0.83\" title=\"-0.036\">tarzan</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 89.94%); opacity: 0.83\" title=\"-0.036\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.42%); opacity: 0.82\" title=\"0.019\">jane</span><span style=\"opacity: 0.80\">&#x27; </span><span style=\"background-color: hsl(0, 100.00%, 90.35%); opacity: 0.83\" title=\"-0.033\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.96%); opacity: 0.86\" title=\"-0.082\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.44%); opacity: 0.84\" title=\"-0.049\">all</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 80.18%); opacity: 0.87\" title=\"0.094\">it</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(120, 100.00%, 84.76%); opacity: 0.85\" title=\"0.064\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.24%); opacity: 0.88\" title=\"0.107\">famous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.45%); opacity: 0.84\" title=\"0.049\">story</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.50%); opacity: 0.88\" title=\"-0.105\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.54%); opacity: 0.88\" title=\"-0.098\">a</span><span style=\"opacity: 0.80\"> child </span><span style=\"background-color: hsl(0, 100.00%, 91.14%); opacity: 0.82\" title=\"-0.030\">reared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 61.97%); opacity: 0.99\" title=\"-0.237\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.23%); opacity: 0.90\" title=\"-0.121\">manhood</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.11%); opacity: 0.82\" title=\"0.030\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.19%); opacity: 0.81\" title=\"0.009\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.99%); opacity: 0.82\" title=\"-0.030\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.62%); opacity: 0.83\" title=\"-0.032\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.41%); opacity: 0.81\" title=\"0.012\">apes</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 86.09%); opacity: 0.84\" title=\"0.056\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.18%); opacity: 0.82\" title=\"-0.020\">titled</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.18%); opacity: 0.82\" title=\"-0.020\">british</span><span style=\"opacity: 0.80\"> couple (</span><span style=\"background-color: hsl(120, 100.00%, 93.82%); opacity: 0.81\" title=\"0.018\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.82%); opacity: 0.81\" title=\"0.018\">wife</span><span style=\"opacity: 0.80\"> pregnant) </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> stranded </span><span style=\"background-color: hsl(120, 100.00%, 91.11%); opacity: 0.82\" title=\"0.030\">in</span><span style=\"opacity: 0.80\"> the african wilds </span><span style=\"background-color: hsl(120, 100.00%, 98.12%); opacity: 0.80\" title=\"0.003\">after</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.51%); opacity: 0.94\" title=\"-0.181\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.255\">shipwreck</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.063\">after</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 86.97%); opacity: 0.84\" title=\"-0.051\">parents</span><span style=\"opacity: 0.80\">&#x27; </span><span style=\"background-color: hsl(0, 100.00%, 80.72%); opacity: 0.87\" title=\"-0.090\">deaths</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 89.35%); opacity: 0.83\" title=\"-0.039\">the</span><span style=\"opacity: 0.80\"> baby </span><span style=\"background-color: hsl(0, 100.00%, 86.50%); opacity: 0.84\" title=\"-0.054\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.02%); opacity: 0.81\" title=\"0.013\">raised</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.44%); opacity: 0.92\" title=\"0.158\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.19%); opacity: 0.81\" title=\"0.009\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.99%); opacity: 0.82\" title=\"-0.030\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.62%); opacity: 0.83\" title=\"-0.032\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.65%); opacity: 0.83\" title=\"-0.037\">apes</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 93.38%); opacity: 0.82\" title=\"-0.020\">twenty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.44%); opacity: 0.86\" title=\"0.072\">years</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.12%); opacity: 0.87\" title=\"-0.094\">later</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.32%); opacity: 0.85\" title=\"-0.061\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.60%); opacity: 0.87\" title=\"0.084\">young</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.93%); opacity: 0.89\" title=\"0.109\">man</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 86.52%); opacity: 0.84\" title=\"0.054\">i</span><span style=\"opacity: 0.80\">.e. tarzan) </span><span style=\"background-color: hsl(0, 100.00%, 90.48%); opacity: 0.83\" title=\"-0.033\">rescues</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.36%); opacity: 0.91\" title=\"-0.143\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.68%); opacity: 0.86\" title=\"-0.071\">wounded</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.91%); opacity: 0.83\" title=\"-0.041\">belgian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.14%); opacity: 0.91\" title=\"-0.144\">explorer</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.67%); opacity: 0.85\" title=\"-0.059\">nursing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.86%); opacity: 0.93\" title=\"0.162\">him</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.94%); opacity: 0.92\" title=\"0.154\">back</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.89%); opacity: 0.89\" title=\"-0.117\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.31%); opacity: 0.85\" title=\"-0.061\">health</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 88.91%); opacity: 0.83\" title=\"-0.041\">belgian</span><span style=\"opacity: 0.80\"> discovers evidence </span><span style=\"background-color: hsl(0, 100.00%, 93.20%); opacity: 0.82\" title=\"-0.020\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.94%); opacity: 0.82\" title=\"-0.021\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.41%); opacity: 0.87\" title=\"-0.085\">rescuer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 81.60%); opacity: 0.87\" title=\"0.084\">young</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.02%); opacity: 0.87\" title=\"-0.088\">lord</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.67%); opacity: 0.91\" title=\"-0.140\">greystoke</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.52%); opacity: 0.85\" title=\"0.066\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.027\">returns</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.23%); opacity: 0.88\" title=\"0.107\">him</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.38%); opacity: 0.87\" title=\"-0.086\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.71%); opacity: 0.83\" title=\"0.042\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.08%); opacity: 0.84\" title=\"0.056\">rightful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.91%); opacity: 0.85\" title=\"-0.057\">estate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.54%); opacity: 0.82\" title=\"-0.028\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.88%); opacity: 0.81\" title=\"-0.017\">scotland</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.77%); opacity: 0.81\" title=\"-0.018\">where</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.10%); opacity: 0.82\" title=\"0.021\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.30%); opacity: 0.81\" title=\"0.012\">must</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.63%); opacity: 0.88\" title=\"-0.104\">adjust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.25%); opacity: 0.84\" title=\"-0.056\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.00%); opacity: 0.93\" title=\"-0.161\">civilized</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.09%); opacity: 0.87\" title=\"-0.087\">society</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.016\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.84%); opacity: 0.84\" title=\"0.052\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.12%); opacity: 0.82\" title=\"-0.025\">sort</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.37%); opacity: 0.83\" title=\"-0.044\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.61%); opacity: 0.86\" title=\"-0.078\">divided</span><span style=\"opacity: 0.80\"> into </span><span style=\"background-color: hsl(120, 100.00%, 86.23%); opacity: 0.84\" title=\"0.056\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.54%); opacity: 0.81\" title=\"-0.008\">parts</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 86.85%); opacity: 0.84\" title=\"0.052\">in</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 91.06%); opacity: 0.82\" title=\"0.030\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.48%); opacity: 0.88\" title=\"-0.105\">half</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 90.24%); opacity: 0.83\" title=\"-0.034\">we</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.72%); opacity: 0.85\" title=\"0.065\">see</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.85%); opacity: 0.85\" title=\"0.064\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.96%); opacity: 0.81\" title=\"-0.017\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.03%); opacity: 0.88\" title=\"-0.101\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.21%); opacity: 0.86\" title=\"-0.074\">jungle</span><span style=\"opacity: 0.80\"> environment. </span><span style=\"background-color: hsl(0, 100.00%, 76.12%); opacity: 0.90\" title=\"-0.122\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.40%); opacity: 0.86\" title=\"-0.073\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.83%); opacity: 0.85\" title=\"-0.070\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.61%); opacity: 0.87\" title=\"-0.091\">expert</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 86.52%); opacity: 0.84\" title=\"0.054\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.61%); opacity: 0.88\" title=\"0.097\">am</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.18%); opacity: 0.84\" title=\"-0.045\">unaware</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.69%); opacity: 0.83\" title=\"-0.042\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.60%); opacity: 0.88\" title=\"-0.097\">to</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 99.39%); opacity: 0.80\" title=\"-0.001\">realism</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.25%); opacity: 0.83\" title=\"0.034\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.14%); opacity: 0.81\" title=\"0.009\">its</span><span style=\"opacity: 0.80\"> depiction </span><span style=\"background-color: hsl(120, 100.00%, 90.25%); opacity: 0.83\" title=\"0.034\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.79%); opacity: 0.81\" title=\"0.018\">ape</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.49%); opacity: 0.84\" title=\"0.054\">community</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.27%); opacity: 0.93\" title=\"0.167\">life</span><span style=\"opacity: 0.80\">, but </span><span style=\"background-color: hsl(120, 100.00%, 80.18%); opacity: 0.87\" title=\"0.094\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> certainly </span><span style=\"background-color: hsl(120, 100.00%, 88.63%); opacity: 0.83\" title=\"0.042\">entertaining</span><span style=\"opacity: 0.80\">. for </span><span style=\"background-color: hsl(120, 100.00%, 82.75%); opacity: 0.86\" title=\"0.077\">me</span><span style=\"opacity: 0.80\">, the </span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.015\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.49%); opacity: 0.89\" title=\"0.119\">moving</span><span style=\"opacity: 0.80\"> section </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.68%); opacity: 0.85\" title=\"-0.059\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.20%); opacity: 0.88\" title=\"-0.107\">second</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.08%); opacity: 0.97\" title=\"-0.219\">half</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 92.78%); opacity: 0.82\" title=\"0.022\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.86%); opacity: 0.92\" title=\"-0.154\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.81%); opacity: 0.85\" title=\"-0.064\">must</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.29%); opacity: 0.83\" title=\"-0.044\">meet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.36%); opacity: 0.84\" title=\"0.049\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.04%); opacity: 0.86\" title=\"0.081\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.93%); opacity: 0.82\" title=\"0.026\">family</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 83.97%); opacity: 0.85\" title=\"0.069\">develop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.16%); opacity: 0.90\" title=\"0.129\">language</span><span style=\"opacity: 0.80\"> skills, </span><span style=\"background-color: hsl(120, 100.00%, 79.14%); opacity: 0.88\" title=\"0.101\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.28%); opacity: 0.81\" title=\"-0.012\">adjust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.44%); opacity: 0.85\" title=\"-0.060\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.55%); opacity: 0.80\" title=\"-0.005\">aristocratic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.47%); opacity: 0.88\" title=\"-0.105\">british</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.72%); opacity: 0.82\" title=\"-0.032\">society</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.46%); opacity: 0.82\" title=\"-0.019\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.052\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.29%); opacity: 0.83\" title=\"0.039\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.67%); opacity: 0.82\" title=\"0.027\">wooing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.91%); opacity: 0.86\" title=\"0.082\">jane</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 84.01%); opacity: 0.85\" title=\"0.069\">andie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.74%); opacity: 0.82\" title=\"-0.027\">macdowell</span><span style=\"opacity: 0.80\">). </span><span style=\"background-color: hsl(120, 100.00%, 93.01%); opacity: 0.82\" title=\"0.021\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.67%); opacity: 0.89\" title=\"-0.111\">portrayed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.41%); opacity: 0.84\" title=\"-0.049\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.50%); opacity: 0.81\" title=\"0.008\">a</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 94.37%); opacity: 0.81\" title=\"-0.015\">noble</span><span style=\"opacity: 0.80\"> savage&#x27;, whether </span><span style=\"background-color: hsl(120, 100.00%, 91.11%); opacity: 0.82\" title=\"0.030\">in</span><span style=\"opacity: 0.80\"> the wild </span><span style=\"background-color: hsl(0, 100.00%, 69.55%); opacity: 0.94\" title=\"-0.173\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.43%); opacity: 0.88\" title=\"-0.099\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.87%); opacity: 0.90\" title=\"-0.124\">elegant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.93%); opacity: 0.86\" title=\"-0.076\">edwardian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.47%); opacity: 0.86\" title=\"-0.078\">parlors</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 75.85%); opacity: 0.90\" title=\"0.124\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.07%); opacity: 0.85\" title=\"-0.068\">contrast</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 86.38%); opacity: 0.84\" title=\"-0.055\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.022\">upper</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.022\">crust</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.59%); opacity: 0.86\" title=\"-0.071\">depicted</span><span style=\"opacity: 0.80\"> as </span><span style=\"background-color: hsl(120, 100.00%, 79.44%); opacity: 0.88\" title=\"0.099\">often</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.002\">far</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.24%); opacity: 0.83\" title=\"-0.044\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.57%); opacity: 0.90\" title=\"-0.126\">barbaric</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.75%); opacity: 0.89\" title=\"-0.118\">than</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.19%); opacity: 0.81\" title=\"0.009\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.54%); opacity: 0.81\" title=\"0.008\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.86%); opacity: 0.86\" title=\"0.082\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.73%); opacity: 0.85\" title=\"-0.064\">left</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 89.19%); opacity: 0.83\" title=\"0.039\">christopher</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.66%); opacity: 0.82\" title=\"-0.023\">lambert</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.10%); opacity: 0.80\" title=\"-0.001\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.14%); opacity: 0.90\" title=\"0.129\">fantastic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.37%); opacity: 0.81\" title=\"-0.012\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.55%); opacity: 0.81\" title=\"-0.019\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.70%); opacity: 0.84\" title=\"0.047\">sympathetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.34%); opacity: 0.83\" title=\"-0.044\">portrayal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.88%); opacity: 0.81\" title=\"-0.010\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.85%); opacity: 0.85\" title=\"0.064\">tarzan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.35%); opacity: 0.81\" title=\"-0.008\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.31%); opacity: 0.84\" title=\"-0.055\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.57%); opacity: 0.82\" title=\"-0.028\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.30%); opacity: 0.81\" title=\"0.008\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.69%); opacity: 0.97\" title=\"0.222\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.16%); opacity: 0.81\" title=\"0.016\">civilized</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.82%); opacity: 0.89\" title=\"-0.110\">environments</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 92.72%); opacity: 0.82\" title=\"-0.022\">he</span><span style=\"opacity: 0.80\"> conveys </span><span style=\"background-color: hsl(120, 100.00%, 91.80%); opacity: 0.82\" title=\"0.027\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.10%); opacity: 0.92\" title=\"0.152\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.83%); opacity: 0.82\" title=\"-0.026\">sense</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.01%); opacity: 0.88\" title=\"0.102\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.99%); opacity: 0.87\" title=\"0.088\">his</span><span style=\"opacity: 0.80\"> confusion </span><span style=\"background-color: hsl(120, 100.00%, 79.14%); opacity: 0.88\" title=\"0.101\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.75%); opacity: 0.83\" title=\"-0.036\">conflict</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 80.34%); opacity: 0.87\" title=\"-0.092\">torn</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.65%); opacity: 0.85\" title=\"-0.059\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.47%); opacity: 0.83\" title=\"-0.038\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.05%); opacity: 0.83\" title=\"-0.040\">between</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.89%); opacity: 0.90\" title=\"-0.131\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.37%); opacity: 0.87\" title=\"0.086\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.12%); opacity: 0.90\" title=\"0.122\">very</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.62%); opacity: 0.87\" title=\"0.091\">different</span><span style=\"opacity: 0.80\"> worlds, </span><span style=\"background-color: hsl(0, 100.00%, 98.80%); opacity: 0.80\" title=\"-0.002\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.62%); opacity: 0.86\" title=\"-0.071\">original</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.79%); opacity: 0.83\" title=\"-0.036\">ape</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.64%); opacity: 0.85\" title=\"0.065\">family</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.64%); opacity: 0.82\" title=\"0.027\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.20%); opacity: 0.81\" title=\"-0.016\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.036\">new</span><span style=\"opacity: 0.80\"> human one. </span><span style=\"background-color: hsl(0, 100.00%, 84.47%); opacity: 0.85\" title=\"-0.066\">sir</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.00%); opacity: 0.87\" title=\"-0.088\">ralph</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.80%); opacity: 0.82\" title=\"-0.022\">richardson</span><span style=\"opacity: 0.80\">, one </span><span style=\"background-color: hsl(0, 100.00%, 94.95%); opacity: 0.81\" title=\"-0.013\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.18%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.87%); opacity: 0.91\" title=\"-0.147\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.20%); opacity: 0.85\" title=\"-0.062\">british</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.59%); opacity: 0.90\" title=\"0.126\">legends</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.73%); opacity: 0.86\" title=\"0.077\">brilliant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.05%); opacity: 0.85\" title=\"-0.063\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.98%); opacity: 0.82\" title=\"0.026\">always</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.22%); opacity: 0.82\" title=\"-0.020\">in</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 97.60%); opacity: 0.80\" title=\"-0.005\">role</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.00%); opacity: 0.80\" title=\"0.006\">of</span><span style=\"opacity: 0.80\"> tarzan&#x27;s </span><span style=\"background-color: hsl(120, 100.00%, 94.31%); opacity: 0.81\" title=\"0.016\">grandfather</span><span style=\"opacity: 0.80\">, the sixth </span><span style=\"background-color: hsl(0, 100.00%, 86.94%); opacity: 0.84\" title=\"-0.052\">earl</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.92%); opacity: 0.90\" title=\"-0.131\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.93%); opacity: 0.90\" title=\"-0.131\">greystoke</span><span style=\"opacity: 0.80\">.  the film </span><span style=\"background-color: hsl(0, 100.00%, 85.43%); opacity: 0.85\" title=\"-0.060\">focuses</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.23%); opacity: 0.81\" title=\"-0.016\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.14%); opacity: 0.89\" title=\"-0.115\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.81%); opacity: 0.86\" title=\"-0.076\">tarzan</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 81.29%); opacity: 0.87\" title=\"0.086\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.52%); opacity: 0.81\" title=\"0.008\">struggles</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.46%); opacity: 0.84\" title=\"-0.049\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.41%); opacity: 0.83\" title=\"-0.033\">adapting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.73%); opacity: 0.88\" title=\"-0.104\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.048\">civilization</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.64%); opacity: 0.82\" title=\"0.027\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.10%); opacity: 0.86\" title=\"-0.074\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.76%); opacity: 0.85\" title=\"-0.058\">inner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.66%); opacity: 0.82\" title=\"0.027\">conflict</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.51%); opacity: 0.82\" title=\"-0.023\">than</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.41%); opacity: 0.85\" title=\"-0.060\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.61%); opacity: 0.87\" title=\"-0.084\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.65%); opacity: 0.84\" title=\"-0.048\">jungle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.11%); opacity: 0.83\" title=\"-0.040\">exploits</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 97.35%); opacity: 0.80\" title=\"-0.005\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.84%); opacity: 0.86\" title=\"0.083\">unusual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.10%); opacity: 0.84\" title=\"-0.056\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.52%); opacity: 0.83\" title=\"-0.038\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.45%); opacity: 0.85\" title=\"0.060\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.33%); opacity: 0.82\" title=\"-0.024\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.66%); opacity: 0.90\" title=\"0.133\">classic</span><span style=\"opacity: 0.80\"> makes </span><span style=\"background-color: hsl(120, 100.00%, 80.18%); opacity: 0.87\" title=\"0.094\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.55%); opacity: 0.81\" title=\"0.015\">both</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.57%); opacity: 0.89\" title=\"-0.119\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.01%); opacity: 0.83\" title=\"-0.035\">typical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.73%); opacity: 0.84\" title=\"0.047\">dramatic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.76%); opacity: 0.84\" title=\"-0.053\">adventure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.76%); opacity: 0.84\" title=\"-0.053\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.33%); opacity: 0.94\" title=\"0.183\">also</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 88.51%); opacity: 0.83\" title=\"-0.043\">above</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.53%); opacity: 0.89\" title=\"0.112\">all</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.96%); opacity: 0.81\" title=\"-0.010\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.57%); opacity: 0.82\" title=\"0.023\">moving</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.85%); opacity: 0.92\" title=\"0.154\">personal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.039\">story</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 82.42%); opacity: 0.86\" title=\"-0.079\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.10%); opacity: 0.84\" title=\"0.045\">wasn</span><span style=\"opacity: 0.80\">&#x27;t </span><span style=\"background-color: hsl(0, 100.00%, 86.87%); opacity: 0.84\" title=\"-0.052\">surprised</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.16%); opacity: 0.88\" title=\"-0.107\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.69%); opacity: 0.82\" title=\"0.032\">note</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.44%); opacity: 0.82\" title=\"-0.028\">here</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.80%); opacity: 0.92\" title=\"-0.155\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.02%); opacity: 0.86\" title=\"-0.075\">its</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.07%); opacity: 0.87\" title=\"-0.088\">director</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.061\">is</span><span style=\"opacity: 0.80\"> the same </span><span style=\"background-color: hsl(120, 100.00%, 91.73%); opacity: 0.82\" title=\"0.027\">individual</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 80.49%); opacity: 0.87\" title=\"-0.091\">hugh</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.75%); opacity: 0.83\" title=\"-0.042\">hudson</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 88.75%); opacity: 0.83\" title=\"-0.042\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.93%); opacity: 0.83\" title=\"0.041\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.45%); opacity: 0.91\" title=\"-0.142\">directed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.48%); opacity: 0.85\" title=\"0.060\">chariots</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.45%); opacity: 0.82\" title=\"0.024\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.22%); opacity: 0.85\" title=\"-0.062\">fire</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 92.35%); opacity: 0.82\" title=\"-0.024\">another</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.25%); opacity: 0.88\" title=\"0.100\">brilliant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.76%); opacity: 0.83\" title=\"0.036\">movie</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvViRNoD-fEx",
        "colab_type": "text"
      },
      "source": [
        "### We can also use Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgoz1-Gf-Mdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "# Dictionary\n",
        "dictionary = Dictionary(train_df_review_tok)\n",
        "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=2000)\n",
        "\n",
        "# corpus\n",
        "corpus_train = [dictionary.doc2bow(doc) for doc in train_df_review_tok]\n",
        "corpus_test = [dictionary.doc2bow(doc) for doc in test_df_review_tok]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjg6m7jz_Hz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "tfidf = TfidfModel(corpus_train)\n",
        "\n",
        "corpus_train_tfidf = tfidf[corpus_train]\n",
        "corpus_test_tfidf =  tfidf[corpus_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oqWCzT8_pRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.lsimodel import LsiModel\n",
        "\n",
        "lsi = LsiModel(corpus_train_tfidf, id2word=dictionary, num_topics=100)\n",
        "\n",
        "corpus_train_lsi = lsi[corpus_train_tfidf]\n",
        "corpus_test_lsi =  lsi[corpus_test_tfidf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlA4PFZEAts5",
        "colab_type": "code",
        "outputId": "15c970fb-5163-48e5-c91a-8847576e5375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.similarities import MatrixSimilarity\n",
        "corpus_train_lsi_dense = MatrixSimilarity(corpus_train_lsi)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Qnb0PVDjLf",
        "colab_type": "code",
        "outputId": "b17038e2-3021-4681-b08e-4fd844781081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "corpus_test_lsi_dense = MatrixSimilarity(corpus_test_lsi)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO81wMOpFjPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZmGIOt__1Mu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a936fd66-9c7b-483b-c3c9-ef8efe66b5ab"
      },
      "source": [
        "clf = MLPClassifier(verbose=True, early_stopping=True)\n",
        "clf.fit(corpus_train_lsi_dense.index, train_df['is_positive'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.60330096\n",
            "Validation score: 0.841200\n",
            "Iteration 2, loss = 0.39347433\n",
            "Validation score: 0.860400\n",
            "Iteration 3, loss = 0.34378995\n",
            "Validation score: 0.858800\n",
            "Iteration 4, loss = 0.33755586\n",
            "Validation score: 0.861200\n",
            "Iteration 5, loss = 0.33584016\n",
            "Validation score: 0.864000\n",
            "Iteration 6, loss = 0.33485918\n",
            "Validation score: 0.860800\n",
            "Iteration 7, loss = 0.33352682\n",
            "Validation score: 0.861200\n",
            "Iteration 8, loss = 0.33225726\n",
            "Validation score: 0.864000\n",
            "Iteration 9, loss = 0.33084456\n",
            "Validation score: 0.865600\n",
            "Iteration 10, loss = 0.32932556\n",
            "Validation score: 0.867200\n",
            "Iteration 11, loss = 0.32777925\n",
            "Validation score: 0.865600\n",
            "Iteration 12, loss = 0.32612884\n",
            "Validation score: 0.864400\n",
            "Iteration 13, loss = 0.32451014\n",
            "Validation score: 0.867200\n",
            "Iteration 14, loss = 0.32284919\n",
            "Validation score: 0.865600\n",
            "Iteration 15, loss = 0.32075100\n",
            "Validation score: 0.870400\n",
            "Iteration 16, loss = 0.31871750\n",
            "Validation score: 0.864800\n",
            "Iteration 17, loss = 0.31709297\n",
            "Validation score: 0.866400\n",
            "Iteration 18, loss = 0.31530319\n",
            "Validation score: 0.868400\n",
            "Iteration 19, loss = 0.31324468\n",
            "Validation score: 0.867600\n",
            "Iteration 20, loss = 0.31144585\n",
            "Validation score: 0.867600\n",
            "Iteration 21, loss = 0.30930543\n",
            "Validation score: 0.869600\n",
            "Iteration 22, loss = 0.30744177\n",
            "Validation score: 0.864800\n",
            "Iteration 23, loss = 0.30556467\n",
            "Validation score: 0.869600\n",
            "Iteration 24, loss = 0.30345540\n",
            "Validation score: 0.869200\n",
            "Iteration 25, loss = 0.30160371\n",
            "Validation score: 0.867200\n",
            "Iteration 26, loss = 0.29981702\n",
            "Validation score: 0.868000\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSDGpk2ANk2",
        "colab_type": "code",
        "outputId": "2a0b947d-39a1-471a-9c1e-782282740700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.score(corpus_test_lsi_dense.index, test_df['is_positive'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9xxR3oK835c",
        "colab_type": "text"
      },
      "source": [
        "## Word embeddings (aka. Word2Vec & Co.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVf0gXp9-T2",
        "colab_type": "text"
      },
      "source": [
        "We will start by using some pretrained vectors that are readily available online. Often these are trained on textdata from Wikipedia and other webdata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk5ptjJQBzA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assigning preloaded model for the seminar\n",
        "\n",
        "model = model_gensim_glove"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62wCNGme-OJ8",
        "colab_type": "code",
        "outputId": "143b94a5-0802-4f42-bc38-504adf2d1f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#import gensim.downloader as api\n",
        "\n",
        "#model = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_X3c0J-8mm",
        "colab_type": "code",
        "outputId": "c42f172b-3ac9-4c35-d05d-b6bca6cb5d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar('student')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('students', 0.7690913677215576),\n",
              " ('teacher', 0.6873654723167419),\n",
              " ('graduate', 0.6737600564956665),\n",
              " ('school', 0.613064706325531),\n",
              " ('college', 0.6090279221534729),\n",
              " ('undergraduate', 0.6043775677680969),\n",
              " ('faculty', 0.5998986959457397),\n",
              " ('university', 0.5970512628555298),\n",
              " ('academic', 0.5810065865516663),\n",
              " ('campus', 0.5767688155174255)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY_XQI1Z_B8K",
        "colab_type": "code",
        "outputId": "4fae2e67-0ac6-4457-8d3c-971bb0b8bd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6713277101516724),\n",
              " ('princess', 0.5432624220848083),\n",
              " ('throne', 0.5386104583740234),\n",
              " ('monarch', 0.5347574949264526),\n",
              " ('daughter', 0.498025119304657),\n",
              " ('mother', 0.4956442713737488),\n",
              " ('elizabeth', 0.4832652509212494),\n",
              " ('kingdom', 0.47747087478637695),\n",
              " ('prince', 0.4668239951133728),\n",
              " ('wife', 0.4647327661514282)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTaV-FVP_g1R",
        "colab_type": "code",
        "outputId": "eb738495-b462-4404-e255-525cca1b1c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar(positive=['france', 'vodka'], negative=['russia'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cognac', 0.5327103734016418),\n",
              " ('champagne', 0.5181883573532104),\n",
              " ('liqueur', 0.5106790661811829),\n",
              " ('bourbon', 0.452729195356369),\n",
              " ('whiskey', 0.4516924321651459),\n",
              " ('bottle', 0.45057547092437744),\n",
              " ('drink', 0.4444752335548401),\n",
              " ('drinks', 0.44175881147384644),\n",
              " ('brandy', 0.43809670209884644),\n",
              " ('wine', 0.43010368943214417)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXKYnAoK_8z2",
        "colab_type": "code",
        "outputId": "8c804060-8460-4b86-af72-3d558c7edd07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar(positive=['france', 'beer'], negative=['germany'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('drink', 0.5580321550369263),\n",
              " ('wine', 0.5453617572784424),\n",
              " ('drinks', 0.5428332090377808),\n",
              " ('champagne', 0.5211746692657471),\n",
              " ('whiskey', 0.502285361289978),\n",
              " ('bottles', 0.4866787791252136),\n",
              " ('bottle', 0.48181623220443726),\n",
              " ('beers', 0.48144668340682983),\n",
              " ('beverage', 0.465888649225235),\n",
              " ('bottled', 0.46392548084259033)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkOr3UujAVpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a little helper function turning input text into it's average vector\n",
        "\n",
        "def get_phrase_embedding(model, phrase):    \n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "    if type(phrase) == str:\n",
        "      phrase = list(map(lambda x: x.lower(), word_tokenize(phrase)))\n",
        "    vecs = [model.get_vector(tok) for tok in phrase if tok in model.wv.vocab]\n",
        "    if len(vecs) == 0:\n",
        "      return vector\n",
        "    else:\n",
        "      vector = sum(vecs)/len(vecs)\n",
        "      return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMZpqqhPAtQP",
        "colab_type": "code",
        "outputId": "e07e786e-3ff0-417b-eb3f-5985051c0f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# some modules needed to prepare our texts\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3faKrHtAhuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1f015c06-4a5f-4aae-8460-6cd27b6f76c7"
      },
      "source": [
        "# vectorizing the train and test-set using average vectors from the pretrained model\n",
        "\n",
        "text_vectors_train = np.array([get_phrase_embedding(model, phrase) for phrase in train_df_review_tok])\n",
        "text_vectors_test = np.array([get_phrase_embedding(model, phrase) for phrase in test_df_review_tok])\n",
        "\n",
        "print(text_vectors_train.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(25000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDDAUXaWDCTO",
        "colab_type": "code",
        "outputId": "ed5034c9-ce4d-4b3d-c4ef-d66d0dfc7a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(text_vectors_train,train_df['is_positive'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOgqE6hoDMIx",
        "colab_type": "code",
        "outputId": "01ea1ad0-eda7-4c30-fb71-2c17e8122efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.score(text_vectors_test,test_df['is_positive'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4P_DzmjDhb7",
        "colab_type": "text"
      },
      "source": [
        "83% is not particularly good. Let's see if we can improve that score using custom trained word embeddings. To accomplish this, we need to slice all our data into sentences which will represent the context of the specific word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBRvy-luayI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first we create a list of reviews\n",
        "texts = list(train_df.review)\n",
        "\n",
        "texts.extend(test_df.review) \n",
        "# alternaltively one could also use the sentences from the test-set\n",
        "# without the test-set data this step is a bit silly but ok..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-8KdAPfcaWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we split the sentences\n",
        "\n",
        "sents = []\n",
        "for text in texts:\n",
        "  sents.extend(sent_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy5Ih4mJaooY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we create tokenized sentenses\n",
        "\n",
        "tokenized_texts = [word_tokenize(text) for text in sents]\n",
        "tokenized_texts = list(map(lambda x: [y.lower() for y in x], tokenized_texts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6WjsZ_9G5o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can use Gensim to train the model\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pza0UtUQb0qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(tokenized_texts, \n",
        "                 size=300,      # embedding vector size\n",
        "                 min_count=10,  # consider words that occured at least 10 times\n",
        "                 window=8,\n",
        "                 max_final_vocab = 3000).wv  # define context as a 5-word window around the target word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSLz2SJOcEP3",
        "colab_type": "code",
        "outputId": "6451f931-6aec-4a9f-a5fb-492ef0c60d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model.most_similar('stupid')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dumb', 0.8275753259658813),\n",
              " ('lame', 0.7437105178833008),\n",
              " ('ridiculous', 0.7312101721763611),\n",
              " ('silly', 0.7006996870040894),\n",
              " ('pathetic', 0.6574733257293701),\n",
              " ('unfunny', 0.6453620791435242),\n",
              " ('unrealistic', 0.6363035440444946),\n",
              " ('corny', 0.636043906211853),\n",
              " ('unbelievable', 0.6325340867042542),\n",
              " ('pointless', 0.6173370480537415)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jL6oVVUF7B-",
        "colab_type": "text"
      },
      "source": [
        "Now that we spent some time training the model, we can use a bit more to have a look at it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PXHXKjEeIsE",
        "colab_type": "code",
        "outputId": "0b4be790-502f-4404-934b-e533ca3f2c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we can print some of the often seen terms\n",
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'him', 'however', 'money', 'budget', 'tries', 'brother', 'light', 'famous', 'comment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX229a1PeMl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the model can also return our word-vectors\n",
        "\n",
        "word_vectors = model.vectors[[model.vocab[word].index for word in words]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MmTZ50Kez7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# little function to visualize the vectors\n",
        "\n",
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXJLn25qeRfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can project the word vectors into 2dimensinoal space using the new UMAP library\n",
        "import umap\n",
        "\n",
        "def get_umap_projection(word_vectors):\n",
        "    vecs = umap.UMAP(n_neighbors=15, metric='cosine').fit_transform(word_vectors)\n",
        "    return vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0U3M3pGe5iW",
        "colab_type": "code",
        "outputId": "b167b9e0-baaf-4e25-eb4d-af30dbca499e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "word_umap = get_umap_projection(word_vectors[:1000])\n",
        "draw_vectors(word_umap[:, 0], word_umap[:, 1], color='blue', token=words)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"bfbf2edf-351b-418b-8f9e-5bb2195092d7\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"82842a86-33d8-4855-9ec6-59ff42c4d419\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"id\":\"1020\",\"type\":\"Grid\"},{\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"id\":\"1039\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1044\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1003\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1007\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1044\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1038\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"},{\"id\":\"1041\",\"type\":\"HoverTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1041\",\"type\":\"HoverTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1037\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1040\",\"type\":\"CDSView\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{\"formatter\":{\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"token\":[\"the\",\",\",\".\",\"and\",\"a\",\"of\",\"to\",\"is\",\"it\",\"in\",\"i\",\"this\",\"that\",\"'s\",\"was\",\"as\",\"with\",\"for\",\"movie\",\"but\",\"film\",\")\",\"(\",\"you\",\"on\",\"``\",\"n't\",\"''\",\"not\",\"are\",\"he\",\"his\",\"have\",\"be\",\"one\",\"!\",\"at\",\"all\",\"they\",\"by\",\"an\",\"who\",\"from\",\"so\",\"like\",\"there\",\"or\",\"just\",\"do\",\"her\",\"about\",\"if\",\"has\",\"out\",\"?\",\"what\",\"some\",\"good\",\"when\",\"more\",\"very\",\"she\",\"would\",\"...\",\"my\",\"even\",\"no\",\"up\",\"time\",\"can\",\"which\",\"only\",\"really\",\"their\",\"see\",\"story\",\"had\",\"were\",\"me\",\"did\",\"we\",\"does\",\"'\",\":\",\"well\",\"-\",\"than\",\"much\",\"could\",\"been\",\"get\",\"other\",\"people\",\"will\",\"bad\",\"great\",\"also\",\"into\",\"because\",\"how\",\"him\",\"most\",\"first\",\"its\",\"them\",\"then\",\"made\",\"way\",\"make\",\"too\",\"any\",\"movies\",\"after\",\"characters\",\"think\",\"watch\",\"character\",\"films\",\"many\",\";\",\"seen\",\"two\",\"being\",\"never\",\"love\",\"acting\",\"where\",\"plot\",\"show\",\"best\",\"know\",\"little\",\"life\",\"ever\",\"your\",\"better\",\"man\",\"off\",\"here\",\"end\",\"scene\",\"still\",\"over\",\"say\",\"these\",\"should\",\"why\",\"scenes\",\"while\",\"--\",\"'ve\",\"something\",\"such\",\"go\",\"through\",\"those\",\"'m\",\"back\",\"now\",\"thing\",\"watching\",\"real\",\"actors\",\"though\",\"years\",\"funny\",\"another\",\"before\",\"actually\",\"nothing\",\"makes\",\"work\",\"find\",\"look\",\"director\",\"going\",\"same\",\"lot\",\"new\",\"few\",\"every\",\"old\",\"again\",\"part\",\"&\",\"'re\",\"us\",\"cast\",\"things\",\"world\",\"want\",\"quite\",\"got\",\"pretty\",\"around\",\"seems\",\"ca\",\"down\",\"young\",\"take\",\"however\",\"enough\",\"fact\",\"both\",\"horror\",\"thought\",\"give\",\"big\",\"own\",\"may\",\"between\",\"long\",\"without\",\"right\",\"music\",\"saw\",\"times\",\"original\",\"always\",\"series\",\"must\",\"guy\",\"comedy\",\"gets\",\"come\",\"almost\",\"role\",\"interesting\",\"whole\",\"least\",\"point\",\"action\",\"done\",\"bit\",\"script\",\"minutes\",\"far\",\"family\",\"might\",\"anything\",\"since\",\"'ll\",\"am\",\"feel\",\"last\",\"probably\",\"performance\",\"kind\",\"away\",\"yet\",\"anyone\",\"fun\",\"girl\",\"worst\",\"rather\",\"tv\",\"sure\",\"woman\",\"each\",\"played\",\"found\",\"making\",\"our\",\"although\",\"especially\",\"believe\",\"having\",\"day\",\"trying\",\"course\",\"everything\",\"dvd\",\"hard\",\"comes\",\"goes\",\"put\",\"maybe\",\"ending\",\"shows\",\"place\",\"different\",\"worth\",\"book\",\"looking\",\"let\",\"screen\",\"main\",\"someone\",\"sense\",\"once\",\"reason\",\"three\",\"looks\",\"'d\",\"actor\",\"watched\",\"everyone\",\"2\",\"set\",\"effects\",\"money\",\"job\",\"play\",\"true\",\"together\",\"10\",\"plays\",\"during\",\"instead\",\"said\",\"audience\",\"later\",\"seem\",\"takes\",\"beautiful\",\"john\",\"american\",\"himself\",\"special\",\"seeing\",\"war\",\"left\",\"version\",\"excellent\",\"idea\",\"night\",\"else\",\"shot\",\"wife\",\"black\",\"fan\",\"simply\",\"house\",\"death\",\"high\",\"completely\",\"nice\",\"poor\",\"used\",\"read\",\"along\",\"year\",\"father\",\"short\",\"mind\",\"men\",\"help\",\"second\",\"either\",\"kids\",\"boring\",\"home\",\"star\",\"friends\",\"need\",\"try\",\"hollywood\",\"enjoy\",\"less\",\"given\",\"use\",\"half\",\"wrong\",\"classic\",\"women\",\"until\",\"performances\",\"stupid\",\"dead\",\"rest\",\"production\",\"truly\",\"next\",\"couple\",\"line\",\"recommend\",\"start\",\"tell\",\"school\",\"remember\",\"awful\",\"came\",\"terrible\",\"understand\",\"getting\",\"camera\",\"perhaps\",\"full\",\"moments\",\"mean\",\"keep\",\"itself\",\"sex\",\"wonderful\",\"person\",\"others\",\"name\",\"episode\",\"video\",\"playing\",\"budget\",\"doing\",\"definitely\",\"often\",\"human\",\"mother\",\"perfect\",\"gives\",\"face\",\"top\",\"children\",\"small\",\"dialogue\",\"lines\",\"early\",\"went\",\"piece\",\"finally\",\"absolutely\",\"case\",\"stars\",\"certainly\",\"title\",\"head\",\"yes\",\"become\",\"boy\",\"liked\",\"worse\",\"friend\",\"sort\",\"entertaining\",\"hope\",\"loved\",\"picture\",\"style\",\"lost\",\"cinema\",\"felt\",\"entire\",\"written\",\"several\",\"live\",\"supposed\",\"laugh\",\"overall\",\"guys\",\"3\",\"problem\",\"oh\",\"against\",\"waste\",\"beginning\",\"sound\",\"based\",\"totally\",\"fans\",\"wanted\",\"care\",\"seemed\",\"humor\",\"direction\",\"dark\",\"despite\",\"lives\",\"example\",\"guess\",\"game\",\"throughout\",\"final\",\"already\",\"lead\",\"becomes\",\"drama\",\"evil\",\"unfortunately\",\"called\",\"turn\",\"low\",\"able\",\"white\",\"history\",\"killer\",\"days\",\"1\",\"fine\",\"wants\",\"quality\",\"son\",\"amazing\",\"michael\",\"horrible\",\"today\",\"writing\",\"under\",\"\\u0096\",\"works\",\"flick\",\"act\",\"wo\",\"tries\",\"kill\",\"viewer\",\"past\",\"turns\",\"enjoyed\",\"gave\",\"side\",\"town\",\"parts\",\"favorite\",\"stuff\",\"brilliant\",\"matter\",\"eyes\",\"behind\",\"expect\",\"car\",\"girls\",\"kid\",\"obviously\",\"child\",\"run\",\"themselves\",\"sometimes\",\"city\",\"genre\",\"starts\",\"myself\",\"killed\",\"soon\",\"directed\",\"heart\",\"thinking\",\"group\",\"says\",\"actress\",\"god\",\"art\",\"late\",\"decent\",\"took\",\"highly\",\"heard\",\"anyway\",\"happens\",\"except\",\"feeling\",\"daughter\",\"experience\",\"etc\",\"fight\",\"moment\",\"leave\",\"blood\",\"extremely\",\"close\",\"stories\",\"told\",\"hour\",\"score\",\"chance\",\"coming\",\"lack\",\"hand\",\"police\",\"involved\",\"roles\",\"happen\",\"wonder\",\"particularly\",\"including\",\"hilarious\",\"save\",\"looked\",\"strong\",\"david\",\"violence\",\"type\",\"living\",\"happened\",\"complete\",\"mr.\",\"attempt\",\"obvious\",\"james\",\"shown\",\"hell\",\"please\",\"simple\",\"taken\",\"ago\",\"robert\",\"serious\",\"murder\",\"stop\",\"cool\",\"voice\",\"song\",\"crap\",\"brother\",\"seriously\",\"across\",\"known\",\"exactly\",\"released\",\"ok\",\"opening\",\"alone\",\"saying\",\"reality\",\"interest\",\"number\",\"usually\",\"none\",\"hero\",\"husband\",\"jokes\",\"cinematography\",\"slow\",\"hours\",\"sad\",\"possible\",\"yourself\",\"annoying\",\"relationship\",\"career\",\"english\",\"wish\",\"order\",\"huge\",\"gore\",\"whose\",\"talent\",\"age\",\"hit\",\"shots\",\"running\",\"cut\",\"ridiculous\",\"4\",\"ends\",\"started\",\"call\",\"view\",\"opinion\",\"major\",\"mostly\",\"body\",\"female\",\"usual\",\"taking\",\"documentary\",\"change\",\"silly\",\"important\",\"beyond\",\"power\",\"5\",\"ones\",\"country\",\"somewhat\",\"knew\",\"novel\",\"knows\",\"words\",\"disappointed\",\"apparently\",\"scary\",\"word\",\"turned\",\"strange\",\"finds\",\"jack\",\"basically\",\"due\",\"level\",\"four\",\"room\",\"attention\",\"rating\",\"talking\",\"problems\",\"upon\",\"happy\",\"television\",\"episodes\",\"clearly\",\"cheap\",\"local\",\"musical\",\"events\",\"sequence\",\"single\",\"miss\",\"british\",\"talk\",\"tells\",\"review\",\"king\",\"light\",\"earth\",\"whether\",\"predictable\",\"modern\",\"songs\",\"add\",\"george\",\"french\",\"entertainment\",\"easily\",\"dialog\",\"sets\",\"future\",\"team\",\"appears\",\"bring\",\"enjoyable\",\"giving\",\"soundtrack\",\"similar\",\"lots\",\"ten\",\"mention\",\"supporting\",\"$\",\"falls\",\"writer\",\"above\",\"needs\",\"message\",\"moving\",\"bunch\",\"surprised\",\"within\",\"romantic\",\"showing\",\"sequel\",\"certain\",\"dull\",\"hate\",\"space\",\"five\",\"clear\",\"tried\",\"filmed\",\"sorry\",\"ways\",\"comic\",\"middle\",\"among\",\"theme\",\"theater\",\"release\",\"parents\",\"storyline\",\"effort\",\"named\",\"monster\",\"thriller\",\"fall\",\"easy\",\"stay\",\"using\",\"comments\",\"sister\",\"gone\",\"lady\",\"deal\",\"richard\",\"typical\",\"near\",\"buy\",\"feels\",\"suspense\",\"peter\",\"kept\",\"subject\",\"doubt\",\"viewers\",\"avoid\",\"working\",\"die\",\"nearly\",\"greatest\",\"elements\",\"means\",\"fantastic\",\"editing\",\"tale\",\"okay\",\"imagine\",\"points\",\"viewing\",\"herself\",\"actual\",\"general\",\"check\",\"realistic\",\"rock\",\"famous\",\"dog\",\"straight\",\"material\",\"brought\",\"move\",\"feature\",\"form\",\"paul\",\"believable\",\"somehow\",\"forget\",\"begins\",\"class\",\"period\",\"tom\",\"mystery\",\"leads\",\"reviews\",\"animation\",\"hear\",\"rent\",\"america\",\"figure\",\"surprise\",\"learn\",\"york\",\"eventually\",\"weak\",\"premise\",\"wait\",\"atmosphere\",\"sequences\",\"crime\",\"eye\",\"particular\",\"expected\",\"doctor\",\"indeed\",\"sit\",\"killing\",\"fast\",\"shame\",\"situation\",\"decided\",\"truth\",\"whatever\",\"follow\",\"lame\",\"difficult\",\"red\",\"society\",\"season\",\"deep\",\"average\",\"imdb\",\"leaves\",\"boys\",\"possibly\",\"lee\",\"poorly\",\"dance\",\"unless\",\"footage\",\"became\",\"emotional\",\"needed\",\"crew\",\"forced\",\"memorable\",\"begin\",\"oscar\",\"otherwise\",\"note\",\"romance\",\"meet\",\"stand\",\"reading\",\"credits\",\"question\",\"minute\",\"open\",\"third\",\"beauty\",\"sexual\",\"features\",\"superb\",\"meets\",\"nature\",\"interested\",\"whom\",\"write\",\"screenplay\",\"hands\",\"cheesy\",\"gay\",\"previous\",\"perfectly\",\"western\",\"nor\",\"comment\",\"masterpiece\",\"island\",\"plus\",\"effect\",\"sounds\",\"laughs\",\"personal\",\"hot\",\"quickly\",\"total\",\"keeps\",\"inside\",\"weird\",\"street\",\"towards\",\"result\",\"male\",\"box\",\"20\",\"incredibly\",\"japanese\",\"earlier\",\"badly\",\"mark\",\"background\",\"battle\",\"worked\",\"mess\",\"realize\",\"de\",\"unique\",\"copy\",\"setting\",\"disney\",\"joe\",\"dr.\",\"air\",\"older\",\"stage\",\"free\",\"crazy\",\"various\",\"following\",\"bill\",\"ask\",\"powerful\",\"plenty\",\"brings\",\"appear\",\"writers\",\"business\",\"development\",\"baby\",\"directors\",\"admit\",\"creepy\",\"directing\",\"acted\",\"fairly\",\"apart\",\"dumb\",\"joke\",\"reasons\",\"water\",\"portrayed\",\"spent\",\"leading\",\"dramatic\",\"front\",\"forward\",\"sci-fi\",\"rich\",\"outside\",\"william\",\"pay\",\"wasted\",\"fire\",\"fails\",\"deserves\",\"cop\",\"girlfriend\",\"success\",\"meant\",\"attempts\",\"'the\",\"ideas\",\"manages\",\"expecting\",\"agree\",\"missing\",\"party\",\"political\",\"fighting\",\"recently\",\"create\",\"caught\",\"return\",\"dream\",\"hardly\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1051\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1050\",\"type\":\"UnionRenderers\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
              "  var render_items = [{\"docid\":\"82842a86-33d8-4855-9ec6-59ff42c4d419\",\"roots\":{\"1002\":\"bfbf2edf-351b-418b-8f9e-5bb2195092d7\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        embed_document(root);\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "      attempts++;\n",
              "      if (attempts > 100) {\n",
              "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting.figure.Figure\">Figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1002', <span id=\"1107\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='1011', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">h_symmetry&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='1016', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;{'value': '#e5e5e5'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;{'value': 1},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_height&nbsp;=&nbsp;400,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_width&nbsp;=&nbsp;600,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[LinearAxis(id='1011', ...), Grid(id='1015', ...), LinearAxis(id='1016', ...), Grid(id='1020', ...), BoxAnnotation(id='1029', ...), GlyphRenderer(id='1039', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'fixed',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='1044', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='1027', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">v_symmetry&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='1003', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='1007', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='1005', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='1009', ...))</div></div></div>\n",
              "<script>\n",
              "(function() {\n",
              "  var expanded = false;\n",
              "  var ellipsis = document.getElementById(\"1107\");\n",
              "  ellipsis.addEventListener(\"click\", function() {\n",
              "    var rows = document.getElementsByClassName(\"1106\");\n",
              "    for (var i = 0; i < rows.length; i++) {\n",
              "      var el = rows[i];\n",
              "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
              "    }\n",
              "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
              "    expanded = !expanded;\n",
              "  });\n",
              "})();\n",
              "</script>\n"
            ],
            "text/plain": [
              "Figure(id='1002', ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCvSva71qZ5E",
        "colab_type": "text"
      },
      "source": [
        "Now let's try to run the classification again. This time using our custom embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1znaCRWKfwzw",
        "colab_type": "code",
        "outputId": "4884947a-98b8-4ceb-8f07-92a05134111f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# again, we transform our tokenized phrases into matrices\n",
        "\n",
        "text_vectors_train = np.array([get_phrase_embedding(model, phrase) for phrase in train_df_review_tok])\n",
        "text_vectors_test = np.array([get_phrase_embedding(model, phrase) for phrase in test_df_review_tok])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lnLIsUfg2NR",
        "colab_type": "code",
        "outputId": "dcb97950-e3ac-4a46-98b5-55806ba2e2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# and again, we fit the model\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(text_vectors_train,train_df['is_positive'])\n",
        "clf.score(text_vectors_test,test_df['is_positive'])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dg15bOLInZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf9f51cf-79e5-419e-bf89-c04380f16e4c"
      },
      "source": [
        "# and again, we fit the model\n",
        "\n",
        "clf = MLPClassifier(verbose=True, early_stopping=True)\n",
        "clf.fit(text_vectors_train,train_df['is_positive'])\n",
        "clf.score(text_vectors_test,test_df['is_positive'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.48849060\n",
            "Validation score: 0.825600\n",
            "Iteration 2, loss = 0.38521487\n",
            "Validation score: 0.836400\n",
            "Iteration 3, loss = 0.36454177\n",
            "Validation score: 0.846000\n",
            "Iteration 4, loss = 0.35740832\n",
            "Validation score: 0.851600\n",
            "Iteration 5, loss = 0.35004167\n",
            "Validation score: 0.849600\n",
            "Iteration 6, loss = 0.34615975\n",
            "Validation score: 0.850400\n",
            "Iteration 7, loss = 0.33987208\n",
            "Validation score: 0.848800\n",
            "Iteration 8, loss = 0.33756224\n",
            "Validation score: 0.853200\n",
            "Iteration 9, loss = 0.33486363\n",
            "Validation score: 0.855600\n",
            "Iteration 10, loss = 0.33188950\n",
            "Validation score: 0.857200\n",
            "Iteration 11, loss = 0.32932309\n",
            "Validation score: 0.853200\n",
            "Iteration 12, loss = 0.32475058\n",
            "Validation score: 0.854800\n",
            "Iteration 13, loss = 0.32280842\n",
            "Validation score: 0.857200\n",
            "Iteration 14, loss = 0.32074636\n",
            "Validation score: 0.856800\n",
            "Iteration 15, loss = 0.32064797\n",
            "Validation score: 0.859200\n",
            "Iteration 16, loss = 0.31777787\n",
            "Validation score: 0.860400\n",
            "Iteration 17, loss = 0.31431635\n",
            "Validation score: 0.852000\n",
            "Iteration 18, loss = 0.31182007\n",
            "Validation score: 0.856400\n",
            "Iteration 19, loss = 0.30995406\n",
            "Validation score: 0.854400\n",
            "Iteration 20, loss = 0.30900833\n",
            "Validation score: 0.850000\n",
            "Iteration 21, loss = 0.30684610\n",
            "Validation score: 0.848800\n",
            "Iteration 22, loss = 0.30362532\n",
            "Validation score: 0.856800\n",
            "Iteration 23, loss = 0.30176104\n",
            "Validation score: 0.860800\n",
            "Iteration 24, loss = 0.30026009\n",
            "Validation score: 0.840400\n",
            "Iteration 25, loss = 0.29916192\n",
            "Validation score: 0.861600\n",
            "Iteration 26, loss = 0.29603592\n",
            "Validation score: 0.858800\n",
            "Iteration 27, loss = 0.29525418\n",
            "Validation score: 0.855600\n",
            "Iteration 28, loss = 0.29359237\n",
            "Validation score: 0.862400\n",
            "Iteration 29, loss = 0.28908158\n",
            "Validation score: 0.854800\n",
            "Iteration 30, loss = 0.28883313\n",
            "Validation score: 0.854000\n",
            "Iteration 31, loss = 0.28762637\n",
            "Validation score: 0.862000\n",
            "Iteration 32, loss = 0.28730471\n",
            "Validation score: 0.857200\n",
            "Iteration 33, loss = 0.28322259\n",
            "Validation score: 0.856400\n",
            "Iteration 34, loss = 0.28066555\n",
            "Validation score: 0.862000\n",
            "Iteration 35, loss = 0.27897962\n",
            "Validation score: 0.856800\n",
            "Iteration 36, loss = 0.27668130\n",
            "Validation score: 0.854000\n",
            "Iteration 37, loss = 0.27612885\n",
            "Validation score: 0.858800\n",
            "Iteration 38, loss = 0.27467094\n",
            "Validation score: 0.857200\n",
            "Iteration 39, loss = 0.27098337\n",
            "Validation score: 0.853200\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHscyNsq833",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF weighted phrase embeddings\n",
        "\n",
        "For our finaly exercise we will combine the idea behind TF-IDF and word embeddings\n",
        "Basically we need to weight the embeddings that are going into the representation of a phrase by the TF-IDF values for the individual tokens.\n",
        "\n",
        "We can achieve it by multiplication of the word-vector matrix with the TF-IDF document matrix\n",
        "\n",
        "The approach shown here is not really useful for larger datasets but is nice for demonstration on the toy dataset in this example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9F94G6vQnXf",
        "colab_type": "code",
        "outputId": "48074506-51fb-4de4-b9b3-174bdb0f3246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# we start by creating a tf-idf document matrix using only the vocabulary that can be found in the embeddings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(vocabulary=model.wv.vocab.keys())\n",
        "\n",
        "tfidf_matrix_train = vectorizer.fit_transform(train_df['review'])\n",
        "tfidf_matrix_test = vectorizer.transform(test_df['review'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoI23jv2wtBw",
        "colab_type": "code",
        "outputId": "57baa171-afab-4457-d533-c33ba5d4a23b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# extract a matching word-vector matrix\n",
        "vecs = np.vstack([model.wv[x] for x in model.wv.vocab.keys()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V_-lHv2RXqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_vecs_train = np.dot(tfidf_matrix_train.toarray(), vecs)\n",
        "doc_vecs_test = np.dot(tfidf_matrix_test.toarray(), vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Fq2HZY1MyX",
        "colab_type": "code",
        "outputId": "f082532f-0724-4794-ab43-b849565ad5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# test the performance - better as before (not much, but still)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(doc_vecs_train, train_df.is_positive)\n",
        "classifier.score(doc_vecs_test, test_df.is_positive)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5VTI56BJeSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = MLPClassifier(verbose=True, early_stopping=True)\n",
        "\n",
        "classifier.fit(doc_vecs_train, train_df.is_positive)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZSayWIuKXr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.score(doc_vecs_test, test_df.is_positive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCKXqJCU1ksY",
        "colab_type": "text"
      },
      "source": [
        "## Finally - semantic search\n",
        "\n",
        "Here we will be trying to identify similar text fragments given low cosine distance of the representing vectors\n",
        "\n",
        "![alt text](https://i1.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cover_post_final.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtp-C9I3jY4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use the existing cosine similarity implimentation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# we will also define a find_nearest function that finds k nearest texts given a query\n",
        "def find_nearest(model, text_vectors, texts, query, k=10):\n",
        "    query = get_phrase_embedding(model, query)\n",
        "    c = cosine_similarity(text_vectors, query.reshape(1,-1))\n",
        "    c = pd.DataFrame(c)\n",
        "    ix = [int(x) for x in c.sort_values(by = 0, ascending=False)[:k].index]\n",
        "    return [texts[x] for x in ix]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSjyYSLY2U_a",
        "colab_type": "text"
      },
      "source": [
        "A little try out on some dummy data. We would expect that the first sentence has a higher similarity to the query than the second."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DebqLp4gIrR1",
        "colab_type": "code",
        "outputId": "0cad8968-4c84-4e79-a2f3-a4054e00891a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was horrible and awful']\n",
        "dummy_quiry = 'this was an excellent movie'\n",
        "\n",
        "dummy_data_embedding = np.array([get_phrase_embedding(model, phrase) for phrase in dummy_data])\n",
        "dummy_quiry_embedding = np.array(get_phrase_embedding(model, dummy_quiry))\n",
        "\n",
        "c = cosine_similarity(dummy_data_embedding, dummy_quiry_embedding.reshape(1,-1))\n",
        "print(c)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7441406 ]\n",
            " [0.54996884]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6zDyPOskcdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fo better readability\n",
        "import textwrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj8hl_jPSdAr",
        "colab_type": "text"
      },
      "source": [
        "Below you can see the results from the semantic search.\n",
        "\n",
        "\n",
        "\n",
        "*   First one using averadge vectors\n",
        "*   Second, using TF-IDF vectors\n",
        "\n",
        "Which one is better? There is quite some overlap in the results. Thus: Hard to say.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMVGoxzmjg2I",
        "colab_type": "code",
        "outputId": "9302dee7-6e13-431f-ca2c-50b9fdcf4d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's try on real data first using our average embedding vectors\n",
        "\n",
        "results = find_nearest(model, text_vectors_train, train_df.review, query=\"cheesy romance\", k=5)\n",
        "\n",
        "for text in results:\n",
        "  print(textwrap.fill(text, 60))\n",
        "  print('\\n')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DD films were damn corny, damn stupid and had a plot which\n",
            "seemed wafer thin but those days they was a plot at least\n",
            "This film isn't just a comedy but a mix of melodrama,\n",
            "romance everything Every drama scene is blown out of\n",
            "proportion The comedy is funny but corny too Yet the film\n",
            "keeps you entertained, those days Govinda films were loud,\n",
            "crass yet they had some funny moments people enjoyed David\n",
            "Dhawan does a okay job Music is okay Govinda acts well in\n",
            "comedy and drama Karisma is decent in parts and annoys in\n",
            "parts Kader is as usual Gulshan, Prem Chopra are typecast\n",
            "Shakti is hilarious\n",
            "\n",
            "\n",
            "This is a great movie for any fan of Hong Kong action\n",
            "movies. Asides from it's little plot, the weak drama and\n",
            "bits of comedy antics, the movie is action packed with gun-\n",
            "fighting and martial arts action. Kept me entertained from\n",
            "beginning until the end. I thought Shannon Lee was awesome\n",
            "in the movie. Having an action director like Corey Yuen is\n",
            "what keeps Hong Kong action going strong. This modern action\n",
            "film is highly recommended!!\n",
            "\n",
            "\n",
            "If you like occasional nudity with junior high school level\n",
            "slap stick comedy, then look no further. Starting at about\n",
            "the halfway point, the beautiful and erotic Arielle Dombasle\n",
            "starts disrobing at every opportunity. That is the only\n",
            "thing that made this movie worth watching. The story is both\n",
            "lame and preposterous, the humor is corny, and character\n",
            "development is basically non-existent.\n",
            "\n",
            "\n",
            "Most action films are crass of Hindi cinema, especially of\n",
            "Sunny and his family  The film is typical Sunny type with\n",
            "bashes, big dialogues and melodrama The film also has\n",
            "typical Rajiv Rai ingredients of many henchmen and a weird\n",
            "villain The starting is okay and then the shift to Kenya is\n",
            "good but then the film goes on and on  The sequence of\n",
            "events move at a slow pace and nothing that great happens\n",
            "They are many stupid scenes like the Kenya policemen are\n",
            "shown like jokers especially Sharat The climax too is\n",
            "prolonged Rajiv Rai does an okay job Music is okay, only 1\n",
            "song works and that is the last TOOFAN Camera-work is good\n",
            "Sunny Deol is as usual, Chunky acts like a monkey while his\n",
            "serious scenes are laughable, Naseer is alright heroines are\n",
            "pure wood Amrish Puri is not even half as scary as he was in\n",
            "TRIDEV the rest are okay\n",
            "\n",
            "\n",
            "This romantic comedy isn't too bad. There are some funny\n",
            "things happening here and there, and there are some rather\n",
            "memorable characters in it. The acting, however, is\n",
            "amateurish (with the exception of the banker). While some\n",
            "scenes are great fun, others are simply embarrassing. In\n",
            "particular, I found the \"romantic\" part of the story poor.\n",
            "All in all, I guess it's worth seeing if you like football\n",
            "and romantic comedies. It's not really a bad movie, and the\n",
            "ending did feel quite good. Just don't expect anything out\n",
            "of the ordinary. Fair enough if you have an hour and a\n",
            "quarter to kill.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3YgVgpM25F3",
        "colab_type": "text"
      },
      "source": [
        "We can try the same with the TF-IDF weighted vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csLkg8Cp3C4N",
        "colab_type": "code",
        "outputId": "33dcb801-98bc-4008-dc94-de327fcae39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's try on real data first using our average embedding vectors\n",
        "\n",
        "results = find_nearest(model, doc_vecs_train, train_df.review, query=\"bad horror\", k=5)\n",
        "\n",
        "for text in results:\n",
        "  print(textwrap.fill(text, 60))\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "One of my best friends brought this movie over one night\n",
            "with the words 'Wanna watch the worst horror movie ever?' I\n",
            "always enjoy a good laugh at a bad horror flick and said\n",
            "yes. I had expected your typical cheesy b-slasher but this\n",
            "was beyond B. This is Z-slasher, the lowest of the low. With\n",
            "obviously low budget, extremely bad acting, bad lightning,\n",
            "no plot, really bad so-called 'special effects', shaky\n",
            "cameras and a horrible soundtrack this makes movies like\n",
            "House of Wax look like Oscar-winning masterpieces. The only\n",
            "good thing about it is about 15 seconds of one of the\n",
            "characters getting topless - she had some very nice tits.\n",
            "Most of what I said during this film was along the lines of\n",
            "'Wow this is actually SO BAD', 'This is the worst movie\n",
            "ever' and 'I'm not drunk enough for this'. So in conclusion:\n",
            "don't waste your time (or money!).\n",
            "\n",
            "\n",
            "I guess I've seen worse films, but that may be becuz I'm so\n",
            "jaded by how standard these bad horror movies are. The\n",
            "killer monster thing is really really bad, basically its a\n",
            "guy in some kind of green body suit. There is much worse\n",
            "acting as far as B movie go, but don't think for a second\n",
            "this was anything stellar, hell no. It actually did have a\n",
            "plot with substance, but was still pretty stupid. Basically\n",
            "its just a bad low budget horror movie. But at least its not\n",
            "as bad as titanic, that movie sucks balls, this one just\n",
            "sucks. The blood looks really fake in this movie. Thats one\n",
            "complaint I have about all the horror of the new millinium,\n",
            "low grade gore, looks stupid. A good gruesome death scene\n",
            "with really fake blood is so stupid. At least there was a\n",
            "nice shower scene\n",
            "\n",
            "\n",
            "As long as you go into this movie knowing that it's\n",
            "terrible: bad acting, bad \"effects,\" bad story, bad...\n",
            "everything, then you'll love it. This is one of my favorite\n",
            "\"goof on\" movies; watch it as a comedy and have a dozen good\n",
            "laughs!\n",
            "\n",
            "\n",
            "\"Sundown:The Vampire in Retreat\" is a rubbish.The acting is\n",
            "terrible,the atmosphere is non-existent and the characters\n",
            "are uninteresting.The only scary thing about this piece of\n",
            "scum is that majority of the IMDb users gave it a 10.This is\n",
            "really horrifying.No gore,no suspense,no\n",
            "violence,nothing.Bruce Cambell(\"The Evil Dead\",\"Intruder\")is\n",
            "completely wasted,the supporting cast is also\n",
            "terrible.Yes,some people may like this picture,especially a\n",
            "mainstream society but hard-core horror fans or gore-hounds\n",
            "won't enjoy this piece of crap.Personally I hate horror\n",
            "comedies,I prefer watching serious horror movies like\n",
            "\"Cannibal Holocaust\" or \"Last House on the Left\".In my\n",
            "opinion,a real horror movie is supposed to be\n",
            "scary,excessively bloody and disturbing,without stupid\n",
            "humour,which usually ruins the whole concept.This one isn't\n",
            "scary,isn't gory,isn't even funny as a comedy,so don't waste\n",
            "your precious time.\n",
            "\n",
            "\n",
            "I really hope that Concorde/New Horizons wasn't trying to\n",
            "make a serious horror, or even action movie when they made\n",
            "Carnosaur 3. The movie is flat-out silly from start to\n",
            "finish. Even the humor in C3 is funny because it's bad.\n",
            "Definitely a high water mark in the 'So Bad it's Good'\n",
            "genre. If you enjoy the very worst of the worst, this is for\n",
            "you.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}